{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbEER_DL5uu1"
   },
   "source": [
    "# Run Text-Only Experiments\n",
    "\n",
    "This notebook shows the end-to-end pipeline to fine-tune pre-trained BERT model for text classification on our dataset.\n",
    "\n",
    "Parts of this pipeline are adapted from [McCormick's and Ryan's Tutorial on BERT Fine-Tuning](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) and the\n",
    "Huggingface `run_mmimdb.py` script to execute the MMBT model. This code can\n",
    "be accessed [here.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxeWeqpC5-CO"
   },
   "source": [
    "## Skip unless on Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbcc0iwU2Z9n",
    "outputId": "02d961a2-ef00-4e39-c22a-33495179508e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wAwUUimTyz58",
    "outputId": "e8973800-b12c-4ae2-dcb7-fe071cbaf3f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "kARAPI3_y9u7",
    "outputId": "e6aab2bf-f4a7-4190-9b32-b4d8f4b4afc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/LAP_MMBT\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/LAP_MMBT'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/LAP_MMBT\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUHI4kEs6Dyi"
   },
   "source": [
    "## Check GPU is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_3rHDZCzCTD",
    "outputId": "77427918-e122-432c-9a77-34c885c6772b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4_WNIuW6KjT"
   },
   "source": [
    "## Install Huggingface Trnasformers and WandB modules\n",
    "\n",
    "These should have been installed during your environment set-up; you only need to run these cells in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5x-N8RUNzoDC",
    "outputId": "71c92a68-968f-432f-e0a0-3017b1efd198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGCIhVcxaCis",
    "outputId": "0e469d70-50d0-4d91-936a-b8abf6292f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.10.18)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.13)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.20.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.6/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (53.0.0)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV0Y4fNaOsew"
   },
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2TvcJ0KYOsew"
   },
   "outputs": [],
   "source": [
    "from textBert_utils import get_train_val_test_data, tokenize_and_encode_data, make_tensor_dataset, make_dataloader, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nljiGS-pTTKI"
   },
   "outputs": [],
   "source": [
    "import textBert_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B8t3xllQn1Qi"
   },
   "outputs": [],
   "source": [
    "import argparse \n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8vvRk6_BOsex"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3AHC-9ZjQjCT"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_AbRMeB69ym"
   },
   "source": [
    "# Set-up Experiment Hyperparameters and Arguments\n",
    "\n",
    "Specify the training, validation, and test files to run the experiment on. The default here is running the model on 'impression' texts.  \n",
    "\n",
    "To re-make the training, validation, and test data, please refer to the information in the **data/** directory.  \n",
    "\n",
    "Change the default values in the parser.add_argument function for the hyperparameters that you want to specify in the following cell or use the default option.  \n",
    "\n",
    "For multiple experiment runs, please make sure to change the `output_dir` argument so that new results don't overwrit existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6p2ZlSYbh4BK"
   },
   "outputs": [],
   "source": [
    "train_file = \"image_labels_impression_frontal_train.csv\"\n",
    "val_file = \"image_labels_impression_frontal_val.csv\"\n",
    "test_file = \"image_labels_impression_frontal_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QvzzL8Vuovw_"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(f'Project Hyperparameters and Other Configurations Argument Parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ibpA7E14oiZE"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Required parameters\n",
    "parser.add_argument(\n",
    "    \"--data_dir\",\n",
    "    default=\"data/csv\",\n",
    "    type=str,\n",
    "    help=\"The input data dir. Should contain the .jsonl files.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_name\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"model identifier from huggingface.co/models\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    default=\"text_only\",\n",
    "    type=str,\n",
    "    help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    ")\n",
    "\n",
    "    \n",
    "parser.add_argument(\n",
    "    \"--config_name\", default=\"bert-base-uncased\", type=str, help=\"Pretrained config name if not the same as model_name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tokenizer_name\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--train_batch_size\", default=32, type=int, help=\"Batch size for training.\")\n",
    "parser.add_argument(\n",
    "    \"--eval_batch_size\", default=32, type=int, help=\"Batch size for evaluation.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_seq_length\",\n",
    "    default=256,\n",
    "    type=int,\n",
    "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "    \"than this will be truncated, sequences shorter will be padded.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_image_embeds\", default=3, type=int, help=\"Number of Image Embeddings from the Image Encoder\"\n",
    ")\n",
    "parser.add_argument(\"--do_train\", default=True, type=bool, help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\", default=True, type=bool, help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\n",
    "    \"--evaluate_during_training\", default=True, type=bool, help=\"Rul evaluation during training at each logging step.\"\n",
    ")\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    ")\n",
    "parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--weight_decay\", default=0.1, type=float, help=\"Weight deay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "parser.add_argument(\n",
    "    \"--num_train_epochs\", default=4.0, type=float, help=\"Total number of training epochs to perform.\"\n",
    ")\n",
    "parser.add_argument(\"--patience\", default=5, type=int, help=\"Patience for Early Stopping.\")\n",
    "parser.add_argument(\n",
    "    \"--max_steps\",\n",
    "    default=-1,\n",
    "    type=int,\n",
    "    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
    ")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "\n",
    "parser.add_argument(\"--logging_steps\", type=int, default=25, help=\"Log every X updates steps.\")\n",
    "parser.add_argument(\"--save_steps\", type=int, default=25, help=\"Save checkpoint every X updates steps.\")\n",
    "parser.add_argument(\n",
    "    \"--eval_all_checkpoints\",\n",
    "    default=True, type=bool,\n",
    "    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--num_workers\", type=int, default=8, help=\"number of worker threads for dataloading\")\n",
    "\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# Setup CUDA, GPU & distributed training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "args.device = device\n",
    "\n",
    "# Setup Train/Val/Test filenames\n",
    "args.train_file = train_file\n",
    "args.val_file = val_file\n",
    "args.test_file = test_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHXt2oRR76zo"
   },
   "source": [
    "### Check that the Args dict contains correct configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MeWSr2B02eY4",
    "outputId": "27089c40-d342-4aed-8495-6bca2e47ccaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adam_epsilon': 1e-08,\n",
       " 'config_name': 'bert-base-uncased',\n",
       " 'data_dir': 'data/csv',\n",
       " 'device': device(type='cuda'),\n",
       " 'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'eval_all_checkpoints': True,\n",
       " 'eval_batch_size': 32,\n",
       " 'evaluate_during_training': True,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'learning_rate': 5e-05,\n",
       " 'logging_steps': 25,\n",
       " 'max_grad_norm': 1.0,\n",
       " 'max_seq_length': 256,\n",
       " 'max_steps': -1,\n",
       " 'model_name': 'bert-base-uncased',\n",
       " 'n_gpu': 1,\n",
       " 'num_image_embeds': 3,\n",
       " 'num_train_epochs': 4.0,\n",
       " 'num_workers': 8,\n",
       " 'output_dir': 'text_only',\n",
       " 'patience': 5,\n",
       " 'save_steps': 25,\n",
       " 'seed': 42,\n",
       " 'test_file': 'image_labels_impression_frontal_test.csv',\n",
       " 'tokenizer_name': 'bert-base-uncased',\n",
       " 'train_batch_size': 32,\n",
       " 'train_file': 'image_labels_impression_frontal_train.csv',\n",
       " 'val_file': 'image_labels_impression_frontal_val.csv',\n",
       " 'warmup_steps': 0,\n",
       " 'weight_decay': 0.1}"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUe1Aej96lbJ"
   },
   "source": [
    "## Set-up WandB\n",
    "\n",
    "We are setting up our code to run more experiments later and would be tracking them in the WandB API. You need to sign up for an account first to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwIuONkRcLsF",
    "outputId": "3ac56ace-b28a-4373-fc22-c3a143d4cea6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlap_mmbtws2021\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "G82FnR5vtAbS",
    "outputId": "51daa6a3-3468-4c85-f1a8-891ce5c5c207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">Train_Impression_Texts</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only/runs/26q43g64\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only/runs/26q43g64</a><br/>\n",
       "                Run data is saved locally in <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_012535-26q43g64</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(name=\"Train_Impression_Texts\", tags=['Impression', 'frontal'], project=\"Text_Only\", notes=\"256 size and 32 batch\", config=args.__dict__, sync_tensorboard=True)\n",
    "run_name = wandb.run.name\n",
    "wandb_config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5abmm7V8FyP"
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L18XRia4z_jc",
    "outputId": "470a7b21-8e50-4232-fae8-812dbec1a1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 1,947\n",
      "\n",
      "Number of val sentences: 649\n",
      "\n",
      "Number of test sentences: 650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, val, test = get_train_val_test_data(wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "HzKIwM7eCJee",
    "outputId": "2f3ce269-36bd-43a3-fffa-7a919e27f06b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459</td>\n",
       "      <td>CXR865_IM-2385-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>443</td>\n",
       "      <td>CXR835_IM-2360-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute radiographic cardiopulmonary process.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956</td>\n",
       "      <td>CXR3828_IM-1932-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary abnormalities.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3035</td>\n",
       "      <td>CXR3273_IM-1554-1001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>cardiomegaly without acute cardiopulmonary abn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2044</td>\n",
       "      <td>CXR21_IM-0729-1001-0001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>heart size normal. mediastinal silhouettes and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                               text\n",
       "0         459  ...                 no acute cardiopulmonary findings.\n",
       "1         443  ...     no acute radiographic cardiopulmonary process.\n",
       "2        1956  ...            no acute cardiopulmonary abnormalities.\n",
       "3        3035  ...  cardiomegaly without acute cardiopulmonary abn...\n",
       "4        2044  ...  heart size normal. mediastinal silhouettes and...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_NfnWPR95Apc",
    "outputId": "846722c6-3211-4073-ae03-f33f8ea3a530"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950</td>\n",
       "      <td>CXR1849_IM-0550-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>CXR42_IM-2063-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary abnormalities. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2482</td>\n",
       "      <td>CXR1493_IM-0318-1001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>stable chest. elevated left diaphragm. two bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1203</td>\n",
       "      <td>CXR2368_IM-0928-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1. no acute cardiopulmonary disease.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>CXR279_IM-1224-1001-0001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1. no evidence of active disease.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                               text\n",
       "0         950  ...                 no acute cardiopulmonary findings.\n",
       "1          22  ...          no acute cardiopulmonary abnormalities. .\n",
       "2        2482  ...  stable chest. elevated left diaphragm. two bul...\n",
       "3        1203  ...               1. no acute cardiopulmonary disease.\n",
       "4         134  ...                  1. no evidence of active disease.\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4dnH95_3VNMw",
    "outputId": "85575f2d-bfd5-4498-c299-813081c1ed75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331</td>\n",
       "      <td>CXR639_IM-2218-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no evidence of active disease.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>CXR201_IM-0660-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary findings. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>CXR3749_IM-1874-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>986</td>\n",
       "      <td>CXR1908_IM-0590-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute cardiopulmonary disease.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1384</td>\n",
       "      <td>CXR2758_IM-1206-1001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>no acute or active cardiac, pulmonary or pleur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                               text\n",
       "0         331  ...                     no evidence of active disease.\n",
       "1          98  ...               no acute cardiopulmonary findings. .\n",
       "2        1918  ...              no acute cardiopulmonary abnormality.\n",
       "3         986  ...                  no acute cardiopulmonary disease.\n",
       "4        1384  ...  no acute or active cardiac, pulmonary or pleur...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyx0BCy9_z8u"
   },
   "source": [
    "# sentences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xLSXvlOc_zT8"
   },
   "outputs": [],
   "source": [
    "train_sentences = train.text.values\n",
    "train_labels = train.label.values\n",
    "\n",
    "val_sentences = val.text.values\n",
    "val_labels = val.label.values\n",
    "\n",
    "test_sentences = test.text.values\n",
    "test_labels = test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bus3yFPvAWHX",
    "outputId": "33ab4bce-6eba-45c2-bf99-cf337cef388b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no acute cardiopulmonary findings.',\n",
       "       'no acute radiographic cardiopulmonary process.',\n",
       "       'no acute cardiopulmonary abnormalities.',\n",
       "       'cardiomegaly without acute cardiopulmonary abnormality.',\n",
       "       'heart size normal. mediastinal silhouettes and pulmonary vascularity are within normal limits. calcified lingular granuloma. no focal consolidations or pleural effusions. no pneumothorax. breast implants there is a moderate wedge xxxx deformity of the midthoracic vertebrae, xxxx t6, age-indeterminate.',\n",
       "       '1. no acute cardiopulmonary process.',\n",
       "       '1. no acute radiographic cardiopulmonary process.',\n",
       "       'normal chest',\n",
       "       'stable chest, no active/acute cardiopulmonary disease.',\n",
       "       '1. low lung volume study with minimal bibasilar atelectasis. stable chest.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9HUNbeWAb8e",
    "outputId": "215ffa5e-2284-49fa-878b-fd9cfb70ab1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkoi56y3EX4e"
   },
   "source": [
    "# Tokenize and Encode with BERT encoder plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xe9z2opBU1W"
   },
   "source": [
    "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
    "3. Map the tokens to their IDs.\n",
    "4. Pad or truncate all sentences to the same length.\n",
    "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
    "\n",
    "These steps are performed inside the `make_tensor_dataset` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49DUwTrmEl43"
   },
   "source": [
    "# Torch dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-QTtgDFEkwD",
    "outputId": "fae76b48-6c7f-4ab2-f922-71aa86ef96ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  no acute cardiopulmonary findings.\n",
      "Token IDs: tensor([  101,  2053, 11325,  4003,  3695, 14289, 13728,  7856,  2854,  9556,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "Original:  no acute cardiopulmonary findings.\n",
      "Token IDs: tensor([  101,  2053, 11325,  4003,  3695, 14289, 13728,  7856,  2854,  9556,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_tensor_dataset(train_sentences, train_labels, wandb_config)\n",
    "val_dataset = make_tensor_dataset(val_sentences, val_labels, wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1j1bQcmEfdD",
    "outputId": "7d28287c-7834-4b05-ff9b-bee3878f7bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,947 training samples\n",
      "  649 validation samples\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(train_dataset):>5,} training samples')\n",
    "print(f'{len(val_dataset):>5,} validation samples')\n",
    "#print(f'{len(test_dataset):>5,} test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTjcmuENFvBS",
    "outputId": "829c0be9-663e-49c7-f953-4fba4a08e147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2053, 11325,  4003,  3695, 14289, 13728,  7856,  2854,  9556,\n",
       "           1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2053, 11325,  2557, 14773,  4003,  3695, 14289, 13728,  7856,\n",
       "           2854,  2832,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2053, 11325,  4003,  3695, 14289, 13728,  7856,  2854, 28828,\n",
       "           1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([0, 0, 0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ray80zREF5nx"
   },
   "source": [
    "Create an iterator for the dataset using the torch DataLoader class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zw8rZBerAJ-a"
   },
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    'train' : make_dataloader(train_dataset, wandb_config, eval=False),\n",
    "    'train_size': len(train_dataset),\n",
    "    'eval' : make_dataloader(val_dataset, wandb_config, eval=True),\n",
    "    'eval_size' : len(val_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zARn-95bGbYc"
   },
   "source": [
    "# Fine Tune BERT for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtnoCExl97Ss"
   },
   "source": [
    "## Setup Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5cd16bmFS1T5"
   },
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "if not os.path.exists(wandb_config.output_dir):\n",
    "    os.makedirs(wandb_config.output_dir)\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "                    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "                    filename=os.path.join(wandb_config.output_dir, f\"{os.path.splitext(wandb_config.train_file)[0]}_logging.txt\"),\n",
    "                    level=logging.INFO)\n",
    "logger.warning(\"device: %s, n_gpu: %s\",\n",
    "        wandb_config.device,\n",
    "        wandb_config.n_gpu\n",
    ")\n",
    "# Set the verbosity to info of the Transformers logger (on main process only):\n",
    "\n",
    "# Set seed\n",
    "set_seed(wandb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsLgoErr-CKX"
   },
   "source": [
    "## Set up the Model and Train\n",
    "\n",
    "The Code will simply train and validate the specified train and validation sets. \n",
    "\n",
    "Outputs and saved checkpoints are saved in the specifed `--output_dir` argument.\n",
    "Tensorboard data are saved in the `runs/` directory with the date and time of the experiment as well as the filename of the train/test data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "178a42745f574ecfa88db65c53552e1d",
      "4b7fe546adba42fc8e83f68a27431f34",
      "6769f64be23c4d45a75229122f0154f5",
      "f9d41f8a064e41dfbd5ed9af21e0548d",
      "effaf59a9dbd4e4998c7466f9b6d44ff",
      "66d5fd6d06c5497f8a86f4e71dce406c",
      "03fa661b348a4bfbaa324182d58b9a23",
      "c5771cd32c124e969dfa2ea5941874be"
     ]
    },
    "id": "BQamR9mcRMFi",
    "outputId": "046eeb64-1295-4b36-f5f4-bbcf2a26e290"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Iteration:   2%|▏         | 1/61 [00:01<01:21,  1.36s/it]\u001b[A\n",
      "Batch Iteration:   3%|▎         | 2/61 [00:02<01:18,  1.33s/it]\u001b[A\n",
      "Batch Iteration:   5%|▍         | 3/61 [00:03<01:16,  1.31s/it]\u001b[A\n",
      "Batch Iteration:   7%|▋         | 4/61 [00:05<01:14,  1.30s/it]\u001b[A\n",
      "Batch Iteration:   8%|▊         | 5/61 [00:06<01:12,  1.30s/it]\u001b[A\n",
      "Batch Iteration:  10%|▉         | 6/61 [00:07<01:11,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  11%|█▏        | 7/61 [00:09<01:09,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  13%|█▎        | 8/61 [00:10<01:08,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  15%|█▍        | 9/61 [00:11<01:06,  1.28s/it]\u001b[A\n",
      "Batch Iteration:  16%|█▋        | 10/61 [00:12<01:05,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  18%|█▊        | 11/61 [00:14<01:04,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  20%|█▉        | 12/61 [00:15<01:03,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  21%|██▏       | 13/61 [00:16<01:02,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  23%|██▎       | 14/61 [00:18<01:00,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  25%|██▍       | 15/61 [00:19<00:59,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  26%|██▌       | 16/61 [00:20<00:58,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  28%|██▊       | 17/61 [00:21<00:56,  1.29s/it]\u001b[A\n",
      "Batch Iteration:  30%|██▉       | 18/61 [00:23<00:55,  1.30s/it]\u001b[A\n",
      "Batch Iteration:  31%|███       | 19/61 [00:24<00:54,  1.30s/it]\u001b[A\n",
      "Batch Iteration:  33%|███▎      | 20/61 [00:25<00:53,  1.30s/it]\u001b[A\n",
      "Batch Iteration:  34%|███▍      | 21/61 [00:27<00:52,  1.30s/it]\u001b[A\n",
      "Batch Iteration:  36%|███▌      | 22/61 [00:28<00:50,  1.30s/it]\u001b[A\n",
      "Batch Iteration:  38%|███▊      | 23/61 [00:29<00:49,  1.31s/it]\u001b[A\n",
      "Batch Iteration:  39%|███▉      | 24/61 [00:31<00:48,  1.31s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:09,  2.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:00<00:09,  2.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:08,  2.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:01<00:08,  2.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:07,  2.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:02<00:07,  2.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:06,  2.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:03<00:06,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:05,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:04<00:05,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:04,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:05<00:04,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:06<00:03,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:06<00:03,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:07<00:02,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:07<00:02,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:08<00:01,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:08<00:01,  1.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:09<00:01,  1.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:09<00:00,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.2008007083620344, \"eval_accuracy\": 0.9352850539291218, \"learning_rate\": 4.487704918032787e-05, \"training_loss\": 0.33485968500375746, \"step\": 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  41%|████      | 25/61 [00:44<03:01,  5.04s/it]\u001b[A\n",
      "Batch Iteration:  43%|████▎     | 26/61 [00:46<02:18,  3.94s/it]\u001b[A\n",
      "Batch Iteration:  44%|████▍     | 27/61 [00:47<01:47,  3.15s/it]\u001b[A\n",
      "Batch Iteration:  46%|████▌     | 28/61 [00:48<01:26,  2.61s/it]\u001b[A\n",
      "Batch Iteration:  48%|████▊     | 29/61 [00:50<01:11,  2.23s/it]\u001b[A\n",
      "Batch Iteration:  49%|████▉     | 30/61 [00:51<01:00,  1.96s/it]\u001b[A\n",
      "Batch Iteration:  51%|█████     | 31/61 [00:52<00:53,  1.77s/it]\u001b[A\n",
      "Batch Iteration:  52%|█████▏    | 32/61 [00:54<00:47,  1.65s/it]\u001b[A\n",
      "Batch Iteration:  54%|█████▍    | 33/61 [00:55<00:43,  1.56s/it]\u001b[A\n",
      "Batch Iteration:  56%|█████▌    | 34/61 [00:56<00:40,  1.50s/it]\u001b[A\n",
      "Batch Iteration:  57%|█████▋    | 35/61 [00:58<00:37,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  59%|█████▉    | 36/61 [00:59<00:35,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  61%|██████    | 37/61 [01:00<00:33,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  62%|██████▏   | 38/61 [01:02<00:31,  1.38s/it]\u001b[A\n",
      "Batch Iteration:  64%|██████▍   | 39/61 [01:03<00:30,  1.38s/it]\u001b[A\n",
      "Batch Iteration:  66%|██████▌   | 40/61 [01:05<00:28,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  67%|██████▋   | 41/61 [01:06<00:27,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  69%|██████▉   | 42/61 [01:07<00:25,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  70%|███████   | 43/61 [01:09<00:24,  1.36s/it]\u001b[A\n",
      "Batch Iteration:  72%|███████▏  | 44/61 [01:10<00:23,  1.36s/it]\u001b[A\n",
      "Batch Iteration:  74%|███████▍  | 45/61 [01:11<00:21,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  75%|███████▌  | 46/61 [01:13<00:20,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  77%|███████▋  | 47/61 [01:14<00:19,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  79%|███████▊  | 48/61 [01:15<00:17,  1.37s/it]\u001b[A\n",
      "Batch Iteration:  80%|████████  | 49/61 [01:17<00:16,  1.37s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:07,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:06,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:07<00:03,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:08<00:02,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.12466654491921265, \"eval_accuracy\": 0.9661016949152542, \"learning_rate\": 3.975409836065574e-05, \"training_loss\": 0.1165430748462677, \"step\": 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  82%|████████▏ | 50/61 [01:31<00:56,  5.16s/it]\u001b[A\n",
      "Batch Iteration:  84%|████████▎ | 51/61 [01:32<00:40,  4.03s/it]\u001b[A\n",
      "Batch Iteration:  85%|████████▌ | 52/61 [01:34<00:29,  3.24s/it]\u001b[A\n",
      "Batch Iteration:  87%|████████▋ | 53/61 [01:35<00:21,  2.69s/it]\u001b[A\n",
      "Batch Iteration:  89%|████████▊ | 54/61 [01:36<00:16,  2.30s/it]\u001b[A\n",
      "Batch Iteration:  90%|█████████ | 55/61 [01:38<00:12,  2.03s/it]\u001b[A\n",
      "Batch Iteration:  92%|█████████▏| 56/61 [01:39<00:09,  1.85s/it]\u001b[A\n",
      "Batch Iteration:  93%|█████████▎| 57/61 [01:41<00:06,  1.72s/it]\u001b[A\n",
      "Batch Iteration:  95%|█████████▌| 58/61 [01:42<00:04,  1.63s/it]\u001b[A\n",
      "Batch Iteration:  97%|█████████▋| 59/61 [01:44<00:03,  1.57s/it]\u001b[A\n",
      "Batch Iteration:  98%|█████████▊| 60/61 [01:45<00:01,  1.53s/it]\u001b[A\n",
      "Batch Iteration: 100%|██████████| 61/61 [01:46<00:00,  1.75s/it]\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.83it/s]\u001b[A\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.83it/s]\u001b[A\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.83it/s]\u001b[A\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:06,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:06<00:05,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.82it/s]\u001b[A\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.83it/s]\u001b[A\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.88it/s]\n",
      "Epoch:  25%|██▌       | 1/4 [01:57<05:53, 117.86s/it]\n",
      "Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Iteration:   2%|▏         | 1/61 [00:01<01:23,  1.40s/it]\u001b[A\n",
      "Batch Iteration:   3%|▎         | 2/61 [00:02<01:22,  1.41s/it]\u001b[A\n",
      "Batch Iteration:   5%|▍         | 3/61 [00:04<01:21,  1.41s/it]\u001b[A\n",
      "Batch Iteration:   7%|▋         | 4/61 [00:05<01:20,  1.41s/it]\u001b[A\n",
      "Batch Iteration:   8%|▊         | 5/61 [00:07<01:19,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  10%|▉         | 6/61 [00:08<01:17,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  11%|█▏        | 7/61 [00:09<01:16,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  13%|█▎        | 8/61 [00:11<01:15,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  15%|█▍        | 9/61 [00:12<01:13,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  16%|█▋        | 10/61 [00:14<01:12,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  18%|█▊        | 11/61 [00:15<01:10,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  20%|█▉        | 12/61 [00:17<01:09,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  21%|██▏       | 13/61 [00:18<01:07,  1.41s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.14479255028778598, \"eval_accuracy\": 0.9722650231124808, \"learning_rate\": 3.463114754098361e-05, \"training_loss\": 0.06046227022074163, \"step\": 75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  23%|██▎       | 14/61 [00:32<04:09,  5.30s/it]\u001b[A\n",
      "Batch Iteration:  25%|██▍       | 15/61 [00:34<03:10,  4.14s/it]\u001b[A\n",
      "Batch Iteration:  26%|██▌       | 16/61 [00:35<02:29,  3.32s/it]\u001b[A\n",
      "Batch Iteration:  28%|██▊       | 17/61 [00:37<02:00,  2.74s/it]\u001b[A\n",
      "Batch Iteration:  30%|██▉       | 18/61 [00:38<01:40,  2.34s/it]\u001b[A\n",
      "Batch Iteration:  31%|███       | 19/61 [00:39<01:26,  2.05s/it]\u001b[A\n",
      "Batch Iteration:  33%|███▎      | 20/61 [00:41<01:16,  1.86s/it]\u001b[A\n",
      "Batch Iteration:  34%|███▍      | 21/61 [00:42<01:08,  1.72s/it]\u001b[A\n",
      "Batch Iteration:  36%|███▌      | 22/61 [00:44<01:03,  1.63s/it]\u001b[A\n",
      "Batch Iteration:  38%|███▊      | 23/61 [00:45<00:59,  1.56s/it]\u001b[A\n",
      "Batch Iteration:  39%|███▉      | 24/61 [00:46<00:55,  1.51s/it]\u001b[A\n",
      "Batch Iteration:  41%|████      | 25/61 [00:48<00:53,  1.48s/it]\u001b[A\n",
      "Batch Iteration:  43%|████▎     | 26/61 [00:49<00:50,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  44%|████▍     | 27/61 [00:51<00:48,  1.44s/it]\u001b[A\n",
      "Batch Iteration:  46%|████▌     | 28/61 [00:52<00:47,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  48%|████▊     | 29/61 [00:53<00:45,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  49%|████▉     | 30/61 [00:55<00:43,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  51%|█████     | 31/61 [00:56<00:42,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  52%|█████▏    | 32/61 [00:58<00:40,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  54%|█████▍    | 33/61 [00:59<00:39,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  56%|█████▌    | 34/61 [01:00<00:37,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  57%|█████▋    | 35/61 [01:02<00:36,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  59%|█████▉    | 36/61 [01:03<00:35,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  61%|██████    | 37/61 [01:05<00:33,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  62%|██████▏   | 38/61 [01:06<00:32,  1.41s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.12908778995985076, \"eval_accuracy\": 0.9661016949152542, \"learning_rate\": 2.9508196721311478e-05, \"training_loss\": 0.04320165743120015, \"step\": 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  64%|██████▍   | 39/61 [01:21<01:59,  5.41s/it]\u001b[A\n",
      "Batch Iteration:  66%|██████▌   | 40/61 [01:22<01:28,  4.22s/it]\u001b[A\n",
      "Batch Iteration:  67%|██████▋   | 41/61 [01:24<01:07,  3.38s/it]\u001b[A\n",
      "Batch Iteration:  69%|██████▉   | 42/61 [01:25<00:52,  2.78s/it]\u001b[A\n",
      "Batch Iteration:  70%|███████   | 43/61 [01:26<00:42,  2.37s/it]\u001b[A\n",
      "Batch Iteration:  72%|███████▏  | 44/61 [01:28<00:35,  2.08s/it]\u001b[A\n",
      "Batch Iteration:  74%|███████▍  | 45/61 [01:29<00:30,  1.88s/it]\u001b[A\n",
      "Batch Iteration:  75%|███████▌  | 46/61 [01:31<00:26,  1.75s/it]\u001b[A\n",
      "Batch Iteration:  77%|███████▋  | 47/61 [01:32<00:23,  1.65s/it]\u001b[A\n",
      "Batch Iteration:  79%|███████▊  | 48/61 [01:33<00:20,  1.58s/it]\u001b[A\n",
      "Batch Iteration:  80%|████████  | 49/61 [01:35<00:18,  1.53s/it]\u001b[A\n",
      "Batch Iteration:  82%|████████▏ | 50/61 [01:36<00:16,  1.49s/it]\u001b[A\n",
      "Batch Iteration:  84%|████████▎ | 51/61 [01:38<00:14,  1.47s/it]\u001b[A\n",
      "Batch Iteration:  85%|████████▌ | 52/61 [01:39<00:13,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  87%|████████▋ | 53/61 [01:41<00:11,  1.44s/it]\u001b[A\n",
      "Batch Iteration:  89%|████████▊ | 54/61 [01:42<00:10,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  90%|█████████ | 55/61 [01:43<00:08,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  92%|█████████▏| 56/61 [01:45<00:07,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  93%|█████████▎| 57/61 [01:46<00:05,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  95%|█████████▌| 58/61 [01:48<00:04,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  97%|█████████▋| 59/61 [01:49<00:02,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  98%|█████████▊| 60/61 [01:50<00:01,  1.42s/it]\u001b[A\n",
      "Batch Iteration: 100%|██████████| 61/61 [01:52<00:00,  1.84s/it]\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.88it/s]\u001b[A\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.84it/s]\u001b[A\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n",
      "Epoch:  50%|█████     | 2/4 [04:01<03:58, 119.46s/it]\n",
      "Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Iteration:   2%|▏         | 1/61 [00:01<01:23,  1.39s/it]\u001b[A\n",
      "Batch Iteration:   3%|▎         | 2/61 [00:02<01:22,  1.39s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.1431316461918565, \"eval_accuracy\": 0.9738058551617874, \"learning_rate\": 2.4385245901639343e-05, \"training_loss\": 0.030613028993830085, \"step\": 125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:   5%|▍         | 3/61 [00:17<05:10,  5.36s/it]\u001b[A\n",
      "Batch Iteration:   7%|▋         | 4/61 [00:18<03:58,  4.18s/it]\u001b[A\n",
      "Batch Iteration:   8%|▊         | 5/61 [00:20<03:07,  3.34s/it]\u001b[A\n",
      "Batch Iteration:  10%|▉         | 6/61 [00:21<02:31,  2.76s/it]\u001b[A\n",
      "Batch Iteration:  11%|█▏        | 7/61 [00:23<02:07,  2.36s/it]\u001b[A\n",
      "Batch Iteration:  13%|█▎        | 8/61 [00:24<01:49,  2.07s/it]\u001b[A\n",
      "Batch Iteration:  15%|█▍        | 9/61 [00:25<01:37,  1.88s/it]\u001b[A\n",
      "Batch Iteration:  16%|█▋        | 10/61 [00:27<01:28,  1.74s/it]\u001b[A\n",
      "Batch Iteration:  18%|█▊        | 11/61 [00:28<01:21,  1.64s/it]\u001b[A\n",
      "Batch Iteration:  20%|█▉        | 12/61 [00:30<01:17,  1.57s/it]\u001b[A\n",
      "Batch Iteration:  21%|██▏       | 13/61 [00:31<01:13,  1.52s/it]\u001b[A\n",
      "Batch Iteration:  23%|██▎       | 14/61 [00:32<01:09,  1.49s/it]\u001b[A\n",
      "Batch Iteration:  25%|██▍       | 15/61 [00:34<01:07,  1.46s/it]\u001b[A\n",
      "Batch Iteration:  26%|██▌       | 16/61 [00:35<01:05,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  28%|██▊       | 17/61 [00:37<01:03,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  30%|██▉       | 18/61 [00:38<01:01,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  31%|███       | 19/61 [00:39<00:59,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  33%|███▎      | 20/61 [00:41<00:58,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  34%|███▍      | 21/61 [00:42<00:56,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  36%|███▌      | 22/61 [00:44<00:54,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  38%|███▊      | 23/61 [00:45<00:53,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  39%|███▉      | 24/61 [00:46<00:52,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  41%|████      | 25/61 [00:48<00:50,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  43%|████▎     | 26/61 [00:49<00:49,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  44%|████▍     | 27/61 [00:51<00:47,  1.41s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.1600328143741492, \"eval_accuracy\": 0.9738058551617874, \"learning_rate\": 1.9262295081967212e-05, \"training_loss\": 0.0065579659095965324, \"step\": 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  46%|████▌     | 28/61 [01:05<02:57,  5.39s/it]\u001b[A\n",
      "Batch Iteration:  48%|████▊     | 29/61 [01:07<02:14,  4.20s/it]\u001b[A\n",
      "Batch Iteration:  49%|████▉     | 30/61 [01:08<01:44,  3.36s/it]\u001b[A\n",
      "Batch Iteration:  51%|█████     | 31/61 [01:10<01:23,  2.77s/it]\u001b[A\n",
      "Batch Iteration:  52%|█████▏    | 32/61 [01:11<01:08,  2.36s/it]\u001b[A\n",
      "Batch Iteration:  54%|█████▍    | 33/61 [01:12<00:58,  2.07s/it]\u001b[A\n",
      "Batch Iteration:  56%|█████▌    | 34/61 [01:14<00:50,  1.88s/it]\u001b[A\n",
      "Batch Iteration:  57%|█████▋    | 35/61 [01:15<00:45,  1.74s/it]\u001b[A\n",
      "Batch Iteration:  59%|█████▉    | 36/61 [01:17<00:41,  1.64s/it]\u001b[A\n",
      "Batch Iteration:  61%|██████    | 37/61 [01:18<00:37,  1.57s/it]\u001b[A\n",
      "Batch Iteration:  62%|██████▏   | 38/61 [01:19<00:35,  1.52s/it]\u001b[A\n",
      "Batch Iteration:  64%|██████▍   | 39/61 [01:21<00:32,  1.49s/it]\u001b[A\n",
      "Batch Iteration:  66%|██████▌   | 40/61 [01:22<00:30,  1.47s/it]\u001b[A\n",
      "Batch Iteration:  67%|██████▋   | 41/61 [01:24<00:28,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  69%|██████▉   | 42/61 [01:25<00:27,  1.44s/it]\u001b[A\n",
      "Batch Iteration:  70%|███████   | 43/61 [01:27<00:25,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  72%|███████▏  | 44/61 [01:28<00:24,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  74%|███████▍  | 45/61 [01:29<00:22,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  75%|███████▌  | 46/61 [01:31<00:21,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  77%|███████▋  | 47/61 [01:32<00:19,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  79%|███████▊  | 48/61 [01:34<00:18,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  80%|████████  | 49/61 [01:35<00:16,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  82%|████████▏ | 50/61 [01:36<00:15,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  84%|████████▎ | 51/61 [01:38<00:14,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  85%|████████▌ | 52/61 [01:39<00:12,  1.41s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.1599634958991027, \"eval_accuracy\": 0.9738058551617874, \"learning_rate\": 1.4139344262295081e-05, \"training_loss\": 0.005946670318953693, \"step\": 175}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  87%|████████▋ | 53/61 [01:54<00:42,  5.34s/it]\u001b[A\n",
      "Batch Iteration:  89%|████████▊ | 54/61 [01:55<00:29,  4.17s/it]\u001b[A\n",
      "Batch Iteration:  90%|█████████ | 55/61 [01:57<00:20,  3.34s/it]\u001b[A\n",
      "Batch Iteration:  92%|█████████▏| 56/61 [01:58<00:13,  2.76s/it]\u001b[A\n",
      "Batch Iteration:  93%|█████████▎| 57/61 [01:59<00:09,  2.35s/it]\u001b[A\n",
      "Batch Iteration:  95%|█████████▌| 58/61 [02:01<00:06,  2.06s/it]\u001b[A\n",
      "Batch Iteration:  97%|█████████▋| 59/61 [02:02<00:03,  1.87s/it]\u001b[A\n",
      "Batch Iteration:  98%|█████████▊| 60/61 [02:04<00:01,  1.73s/it]\u001b[A\n",
      "Batch Iteration: 100%|██████████| 61/61 [02:05<00:00,  2.05s/it]\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.89it/s]\u001b[A\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.88it/s]\u001b[A\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.92it/s]\n",
      "Epoch:  75%|███████▌  | 3/4 [06:17<02:04, 124.51s/it]\n",
      "Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Iteration:   2%|▏         | 1/61 [00:01<01:22,  1.38s/it]\u001b[A\n",
      "Batch Iteration:   3%|▎         | 2/61 [00:02<01:21,  1.39s/it]\u001b[A\n",
      "Batch Iteration:   5%|▍         | 3/61 [00:04<01:20,  1.40s/it]\u001b[A\n",
      "Batch Iteration:   7%|▋         | 4/61 [00:05<01:19,  1.40s/it]\u001b[A\n",
      "Batch Iteration:   8%|▊         | 5/61 [00:07<01:18,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  10%|▉         | 6/61 [00:08<01:17,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  11%|█▏        | 7/61 [00:09<01:15,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  13%|█▎        | 8/61 [00:11<01:14,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  15%|█▍        | 9/61 [00:12<01:13,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  16%|█▋        | 10/61 [00:14<01:11,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  18%|█▊        | 11/61 [00:15<01:10,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  20%|█▉        | 12/61 [00:16<01:09,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  21%|██▏       | 13/61 [00:18<01:07,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  23%|██▎       | 14/61 [00:19<01:06,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  25%|██▍       | 15/61 [00:21<01:04,  1.40s/it]\u001b[A\n",
      "Batch Iteration:  26%|██▌       | 16/61 [00:22<01:03,  1.40s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.14155679393886766, \"eval_accuracy\": 0.9768875192604006, \"learning_rate\": 9.016393442622952e-06, \"training_loss\": 0.005091448593884706, \"step\": 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  28%|██▊       | 17/61 [00:36<03:54,  5.33s/it]\u001b[A\n",
      "Batch Iteration:  30%|██▉       | 18/61 [00:38<02:59,  4.16s/it]\u001b[A\n",
      "Batch Iteration:  31%|███       | 19/61 [00:39<02:19,  3.33s/it]\u001b[A\n",
      "Batch Iteration:  33%|███▎      | 20/61 [00:41<01:52,  2.75s/it]\u001b[A\n",
      "Batch Iteration:  34%|███▍      | 21/61 [00:42<01:33,  2.35s/it]\u001b[A\n",
      "Batch Iteration:  36%|███▌      | 22/61 [00:44<01:20,  2.07s/it]\u001b[A\n",
      "Batch Iteration:  38%|███▊      | 23/61 [00:45<01:11,  1.87s/it]\u001b[A\n",
      "Batch Iteration:  39%|███▉      | 24/61 [00:46<01:04,  1.73s/it]\u001b[A\n",
      "Batch Iteration:  41%|████      | 25/61 [00:48<00:58,  1.63s/it]\u001b[A\n",
      "Batch Iteration:  43%|████▎     | 26/61 [00:49<00:54,  1.56s/it]\u001b[A\n",
      "Batch Iteration:  44%|████▍     | 27/61 [00:51<00:51,  1.51s/it]\u001b[A\n",
      "Batch Iteration:  46%|████▌     | 28/61 [00:52<00:48,  1.48s/it]\u001b[A\n",
      "Batch Iteration:  48%|████▊     | 29/61 [00:53<00:46,  1.46s/it]\u001b[A\n",
      "Batch Iteration:  49%|████▉     | 30/61 [00:55<00:44,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  51%|█████     | 31/61 [00:56<00:43,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  52%|█████▏    | 32/61 [00:58<00:41,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  54%|█████▍    | 33/61 [00:59<00:39,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  56%|█████▌    | 34/61 [01:00<00:38,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  57%|█████▋    | 35/61 [01:02<00:36,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  59%|█████▉    | 36/61 [01:03<00:35,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  61%|██████    | 37/61 [01:05<00:33,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  62%|██████▏   | 38/61 [01:06<00:32,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  64%|██████▍   | 39/61 [01:07<00:31,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  66%|██████▌   | 40/61 [01:09<00:29,  1.41s/it]\u001b[A\n",
      "Batch Iteration:  67%|██████▋   | 41/61 [01:10<00:28,  1.41s/it]\u001b[A\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 0.1451291164641069, \"eval_accuracy\": 0.9768875192604006, \"learning_rate\": 3.89344262295082e-06, \"training_loss\": 0.0003894365415908396, \"step\": 225}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Iteration:  69%|██████▉   | 42/61 [01:25<01:42,  5.37s/it]\u001b[A\n",
      "Batch Iteration:  70%|███████   | 43/61 [01:26<01:15,  4.19s/it]\u001b[A\n",
      "Batch Iteration:  72%|███████▏  | 44/61 [01:28<00:56,  3.35s/it]\u001b[A\n",
      "Batch Iteration:  74%|███████▍  | 45/61 [01:29<00:44,  2.77s/it]\u001b[A\n",
      "Batch Iteration:  75%|███████▌  | 46/61 [01:31<00:35,  2.36s/it]\u001b[A\n",
      "Batch Iteration:  77%|███████▋  | 47/61 [01:32<00:29,  2.07s/it]\u001b[A\n",
      "Batch Iteration:  79%|███████▊  | 48/61 [01:33<00:24,  1.88s/it]\u001b[A\n",
      "Batch Iteration:  80%|████████  | 49/61 [01:35<00:20,  1.74s/it]\u001b[A\n",
      "Batch Iteration:  82%|████████▏ | 50/61 [01:36<00:18,  1.64s/it]\u001b[A\n",
      "Batch Iteration:  84%|████████▎ | 51/61 [01:38<00:15,  1.57s/it]\u001b[A\n",
      "Batch Iteration:  85%|████████▌ | 52/61 [01:39<00:13,  1.52s/it]\u001b[A\n",
      "Batch Iteration:  87%|████████▋ | 53/61 [01:40<00:11,  1.49s/it]\u001b[A\n",
      "Batch Iteration:  89%|████████▊ | 54/61 [01:42<00:10,  1.46s/it]\u001b[A\n",
      "Batch Iteration:  90%|█████████ | 55/61 [01:43<00:08,  1.45s/it]\u001b[A\n",
      "Batch Iteration:  92%|█████████▏| 56/61 [01:45<00:07,  1.44s/it]\u001b[A\n",
      "Batch Iteration:  93%|█████████▎| 57/61 [01:46<00:05,  1.43s/it]\u001b[A\n",
      "Batch Iteration:  95%|█████████▌| 58/61 [01:47<00:04,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  97%|█████████▋| 59/61 [01:49<00:02,  1.42s/it]\u001b[A\n",
      "Batch Iteration:  98%|█████████▊| 60/61 [01:50<00:01,  1.42s/it]\u001b[A\n",
      "Batch Iteration: 100%|██████████| 61/61 [01:51<00:00,  1.84s/it]\n",
      "\n",
      "Batch Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "Batch Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.90it/s]\u001b[A\n",
      "Batch Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.87it/s]\u001b[A\n",
      "Batch Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.87it/s]\u001b[A\n",
      "Batch Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.86it/s]\u001b[A\n",
      "Batch Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.85it/s]\u001b[A\n",
      "Batch Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.83it/s]\u001b[A\n",
      "Batch Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.83it/s]\u001b[A\n",
      "Batch Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.83it/s]\u001b[A\n",
      "Batch Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\n",
      "Batch Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.84it/s]\u001b[A\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n",
      "Epoch: 100%|██████████| 4/4 [08:20<00:00, 125.10s/it]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 617<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178a42745f574ecfa88db65c53552e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_012535-26q43g64/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_012535-26q43g64/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">Train_Impression_Texts</strong>: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only/runs/26q43g64\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only/runs/26q43g64</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up model\n",
    "transformer_config = AutoConfig.from_pretrained(wandb_config.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        wandb_config.tokenizer_name,\n",
    "        do_lower_case=True,\n",
    "        cache_dir=None,\n",
    "    )\n",
    "transformer_model = AutoModelForSequenceClassification.from_pretrained(wandb_config.model_name, config=transformer_config)\n",
    "transformer_model.to(device)\n",
    "logger.info(f\"Training/evaluation parameters: {wandb_config}\")\n",
    "# Training\n",
    "if wandb_config.do_train:\n",
    "    global_step, tr_loss = textBert_utils.train(data_loaders, wandb_config, transformer_model)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "    logger.info(\"Saving model checkpoint to %s\", wandb_config.output_dir)\n",
    "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "    # They can then be reloaded using `from_pretrained()`\n",
    "    model_to_save = (transformer_model.module if hasattr(transformer_model, \"module\") else transformer_model)  # Take care of distributed/parallel training\n",
    "    torch.save(model_to_save.state_dict(), os.path.join(wandb_config.output_dir, WEIGHTS_NAME))\n",
    "    tokenizer.save_pretrained(wandb_config.output_dir)\n",
    "    transformer_config.save_pretrained(wandb_config.output_dir)\n",
    "\n",
    "    # Good practice: save your training arguments together with the trained model\n",
    "    torch.save(args, os.path.join(wandb_config.output_dir, \"training_args.bin\"))\n",
    "\n",
    "    # Load a trained model and vocabulary that you have fine-tuned\n",
    "    transformer_model = AutoModelForSequenceClassification.from_pretrained(wandb_config.model_name, config=transformer_config)\n",
    "    transformer_model.load_state_dict(torch.load(os.path.join(wandb_config.output_dir, WEIGHTS_NAME)))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(wandb_config.output_dir)\n",
    "    transformer_model.to(device)\n",
    "logger.info(\"***** Training Finished *****\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3HT1vZmofkp"
   },
   "source": [
    "# Evaluation on Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOur0pn-oiay"
   },
   "source": [
    "## tokenizer and prepare test dataset\n",
    "\n",
    "use the saved tokenizer from the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "referenced_widgets": [
      "7ebe02aa11d04477ab6c296f10cde34c",
      "20d1a6724be1451aa5b62310f1f0cf00",
      "69479f3cc24d4493a930f19a27d0b432",
      "644afd875c7b4fe0ac363a30e20760fb",
      "96ebfd123dc64f60b2e7dc0ee67a50ca",
      "098610873f5740e58612aaf070ac888c",
      "cb653bfecd3f4c2ba57f4ca7422bf6b2",
      "853be75de5d64a10b2634a8496d894e8"
     ]
    },
    "id": "w-kuN61ooW1v",
    "outputId": "3094dfd2-ded3-4740-b31d-d91d5b827540"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:l3l6tzpm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 908<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebe02aa11d04477ab6c296f10cde34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_014235-l3l6tzpm/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_014235-l3l6tzpm/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">Test_Impression_Texts</strong>: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only/runs/l3l6tzpm\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only/runs/l3l6tzpm</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:l3l6tzpm). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">Test_Impression_Texts</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only/runs/amqevtrp\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only/runs/amqevtrp</a><br/>\n",
       "                Run data is saved locally in <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_014359-amqevtrp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(name=\"Test_Impression_Texts\", tags=['Impression', 'frontal'], project=\"Text_Only\", notes=\"256 size and 32 batch\", config=args.__dict__, sync_tensorboard=True)\n",
    "# wandb.tensorboard.patch(root_logdir=\"...\")\n",
    "run_name = wandb.run.name\n",
    "wandb_config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6K5T2jEpJQx",
    "outputId": "a1772e96-13fa-4765-d1f1-7bc98844e875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  no evidence of active disease.\n",
      "Token IDs: tensor([ 101, 2053, 3350, 1997, 3161, 4295, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "test_dataset = make_tensor_dataset(test_sentences, test_labels, wandb_config, saved_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "k2dCKWr-oheZ"
   },
   "outputs": [],
   "source": [
    "data_loaders['test'] = make_dataloader(test_dataset, wandb_config, eval=True)\n",
    "data_loaders['test_size'] = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4e4fd24584194a3cb273da99d543a230",
      "f65a412b3d334a0885045a4b6ab2bc71",
      "df53a3ec6cde40e4a0d07ea2ce67ca2c",
      "02352cc3746340639afd5977a98d16f7",
      "ea244d1ec88345e6acac84ba1a96c95b",
      "d5d035dcebe74bcd8cf11073af21adcf",
      "4a25d2c49ea14dd8bbbb75772085c334",
      "4b20a74d566e46e0b6386bd5ebf3ccd8"
     ]
    },
    "id": "tFrWAi5AvjWs",
    "outputId": "ce5804ea-c394-4e56-a47c-bc0ed842e3b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:09<00:00,  2.10it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.05it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.04it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.02it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.01it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.98it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.98it/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
      "Batch Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 956<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4fd24584194a3cb273da99d543a230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_014359-amqevtrp/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/content/drive/My Drive/LAP_MMBT/wandb/run-20210215_014359-amqevtrp/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">Test_Impression_Texts</strong>: <a href=\"https://wandb.ai/lap_mmbtws2021/Text_Only/runs/amqevtrp\" target=\"_blank\">https://wandb.ai/lap_mmbtws2021/Text_Only/runs/amqevtrp</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "results = {}\n",
    "if wandb_config.do_eval:\n",
    "    checkpoints = [wandb_config.output_dir]\n",
    "    if wandb_config.eval_all_checkpoints:\n",
    "        checkpoints = list(os.path.dirname(c) \n",
    "        for c in sorted(glob.glob(wandb_config.output_dir + \"/**/\" + \n",
    "                                  WEIGHTS_NAME, recursive=False)))\n",
    "        # recursive=False because otherwise the parent diretory gets included\n",
    "        # which is not what we want; only subdirectories\n",
    "\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "        prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "        transformer_model = AutoModelForSequenceClassification.from_pretrained(wandb_config.model_name, config=transformer_config)\n",
    "        checkpoint = os.path.join(checkpoint, 'pytorch_model.bin')\n",
    "        transformer_model.load_state_dict(torch.load(checkpoint))\n",
    "        transformer_model.to(wandb_config.device)\n",
    "        result = textBert_utils.evaluate(data_loaders, wandb_config, transformer_model, prefix=prefix, test=True) # test=True uses the test_dataset not val_dataset\n",
    "        result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)\n",
    "    logger.info(\"***** Evaluation on Test Data Finished *****\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PBlhF6N_GUj"
   },
   "source": [
    "## Saving Test Eval Results\n",
    "\n",
    "The code automatically saved evaluation result from each checkpoint in its respective folder. This next cell simply saves all of them in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "oJq2ZUXBmsXW"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(args.output_dir, f\"{os.path.splitext(args.test_file)[0]}_eval_results.txt\"), mode='w', encoding='utf-8') as out_f:\n",
    "    print(results, file=out_f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_bert_text_only.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02352cc3746340639afd5977a98d16f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b20a74d566e46e0b6386bd5ebf3ccd8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a25d2c49ea14dd8bbbb75772085c334",
      "value": 1
     }
    },
    "03fa661b348a4bfbaa324182d58b9a23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "098610873f5740e58612aaf070ac888c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "178a42745f574ecfa88db65c53552e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6769f64be23c4d45a75229122f0154f5",
       "IPY_MODEL_f9d41f8a064e41dfbd5ed9af21e0548d"
      ],
      "layout": "IPY_MODEL_4b7fe546adba42fc8e83f68a27431f34"
     }
    },
    "20d1a6724be1451aa5b62310f1f0cf00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a25d2c49ea14dd8bbbb75772085c334": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b20a74d566e46e0b6386bd5ebf3ccd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b7fe546adba42fc8e83f68a27431f34": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e4fd24584194a3cb273da99d543a230": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df53a3ec6cde40e4a0d07ea2ce67ca2c",
       "IPY_MODEL_02352cc3746340639afd5977a98d16f7"
      ],
      "layout": "IPY_MODEL_f65a412b3d334a0885045a4b6ab2bc71"
     }
    },
    "644afd875c7b4fe0ac363a30e20760fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_853be75de5d64a10b2634a8496d894e8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb653bfecd3f4c2ba57f4ca7422bf6b2",
      "value": 1
     }
    },
    "66d5fd6d06c5497f8a86f4e71dce406c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6769f64be23c4d45a75229122f0154f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66d5fd6d06c5497f8a86f4e71dce406c",
      "placeholder": "​",
      "style": "IPY_MODEL_effaf59a9dbd4e4998c7466f9b6d44ff",
      "value": " 0.06MB of 0.06MB uploaded (0.00MB deduped)\r"
     }
    },
    "69479f3cc24d4493a930f19a27d0b432": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_098610873f5740e58612aaf070ac888c",
      "placeholder": "​",
      "style": "IPY_MODEL_96ebfd123dc64f60b2e7dc0ee67a50ca",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "7ebe02aa11d04477ab6c296f10cde34c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_69479f3cc24d4493a930f19a27d0b432",
       "IPY_MODEL_644afd875c7b4fe0ac363a30e20760fb"
      ],
      "layout": "IPY_MODEL_20d1a6724be1451aa5b62310f1f0cf00"
     }
    },
    "853be75de5d64a10b2634a8496d894e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96ebfd123dc64f60b2e7dc0ee67a50ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5771cd32c124e969dfa2ea5941874be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb653bfecd3f4c2ba57f4ca7422bf6b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5d035dcebe74bcd8cf11073af21adcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df53a3ec6cde40e4a0d07ea2ce67ca2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5d035dcebe74bcd8cf11073af21adcf",
      "placeholder": "​",
      "style": "IPY_MODEL_ea244d1ec88345e6acac84ba1a96c95b",
      "value": " 0.04MB of 0.04MB uploaded (0.00MB deduped)\r"
     }
    },
    "ea244d1ec88345e6acac84ba1a96c95b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "effaf59a9dbd4e4998c7466f9b6d44ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f65a412b3d334a0885045a4b6ab2bc71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9d41f8a064e41dfbd5ed9af21e0548d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5771cd32c124e969dfa2ea5941874be",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03fa661b348a4bfbaa324182d58b9a23",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
