{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_mmbt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bbc787eca2344ba9e86f2f2c08da546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0fde5333d14f47039f0b7f498abe2d4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c944a250a63840a1bceb7a5737e60f44",
              "IPY_MODEL_f33f21d6394c47bc98bcaabb7b5ff841"
            ]
          }
        },
        "0fde5333d14f47039f0b7f498abe2d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c944a250a63840a1bceb7a5737e60f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f757bdb31d9a4411947ef247e51e8a37",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fa645744d444308b76e2910abfe3c7c"
          }
        },
        "f33f21d6394c47bc98bcaabb7b5ff841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_362b061f765845478e192e298d146b5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:15&lt;00:00, 28.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9acb0b1810c24a3a95f40a4e28236a15"
          }
        },
        "f757bdb31d9a4411947ef247e51e8a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fa645744d444308b76e2910abfe3c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "362b061f765845478e192e298d146b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9acb0b1810c24a3a95f40a4e28236a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2eb2f22ab5ee484fb3ae55f7c8a5539d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f44a07efefa42eeb9da885bd28e0867",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2720413f26c4423afe7bb76fe6b81d7",
              "IPY_MODEL_918ac453c8684157b5acac8ee2ed3b5f"
            ]
          }
        },
        "6f44a07efefa42eeb9da885bd28e0867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2720413f26c4423afe7bb76fe6b81d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1ae447a85c645a58fece46bab169764",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1daa1a89fb46429194709962710d9b0c"
          }
        },
        "918ac453c8684157b5acac8ee2ed3b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7922eee3e3b94f8d96ec8012351bcfd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 338kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b270d59df2db4c3aa51f5d6bec8f2a11"
          }
        },
        "b1ae447a85c645a58fece46bab169764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1daa1a89fb46429194709962710d9b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7922eee3e3b94f8d96ec8012351bcfd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b270d59df2db4c3aa51f5d6bec8f2a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76f1ce7ff972417fa783bb47bcbea288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3cf4c515055441ca3cf88e508961e19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5af2ccd2c6446cd8f380513acf8f8b9",
              "IPY_MODEL_b77648d304c74c50a2b5b24c859c7245"
            ]
          }
        },
        "c3cf4c515055441ca3cf88e508961e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5af2ccd2c6446cd8f380513acf8f8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15ed30801e884c4886988da0b2febd24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0eb6a99fd54546a18bb501c0339e4024"
          }
        },
        "b77648d304c74c50a2b5b24c859c7245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c67a7ea396144bf1b70f69ede7a804bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:14&lt;00:00, 33.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3caa2641b954ee8bb1b63ebaadde2d8"
          }
        },
        "15ed30801e884c4886988da0b2febd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0eb6a99fd54546a18bb501c0339e4024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c67a7ea396144bf1b70f69ede7a804bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3caa2641b954ee8bb1b63ebaadde2d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "600aa6ce4b344deb9552f7d4fc9b3435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_321fa705c8c641b783af0126f9972847",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf0cd0d3375b4e7b8268a9e24e535662",
              "IPY_MODEL_745db171650246e4a042877786e4a4f3"
            ]
          }
        },
        "321fa705c8c641b783af0126f9972847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf0cd0d3375b4e7b8268a9e24e535662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9f99c6855ed4dfeb5c3e2bcfe6bf99e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_344d87921ba8483c84ddb55c060f4b75"
          }
        },
        "745db171650246e4a042877786e4a4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4936ef401a27409296544986eead1ae8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 66.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c2762b75f8d4b7fad14830761a15db2"
          }
        },
        "b9f99c6855ed4dfeb5c3e2bcfe6bf99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "344d87921ba8483c84ddb55c060f4b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4936ef401a27409296544986eead1ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c2762b75f8d4b7fad14830761a15db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOnHITFCd61k"
      },
      "source": [
        "# Run MMBT Experiments\n",
        "\n",
        "This notebook shows the end-to-end pipeline to fine-tune pre-trained MMBT model for multimodal (text and image) classification on our dataset.\n",
        "\n",
        "Parts of this pipeline are adapted from the\n",
        "Huggingface `run_mmimdb.py` script to execute the MMBT model. This code can\n",
        "be accessed [here.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CArCZbzeM5J"
      },
      "source": [
        "## Skip unless on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG3qBIrWMnyJ",
        "outputId": "2a0fb79e-7e28-456f-9d7b-93b45da57db3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Y8fISAPBm1vW",
        "outputId": "b5b4e88a-66e3-4d3a-bb5c-9f1fa0de01c9"
      },
      "source": [
        "%cd /content/drive/MyDrive/LAP_MMBT\n",
        "%pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/LAP_MMBT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/LAP_MMBT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK2BAFISn86n"
      },
      "source": [
        "Before running the cell below, make sure to select 'GPU' runtime type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfB8X3Ldn7Ci",
        "outputId": "66149a60-e088-4c26-9597-e4e7b1b84711"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcFSbljwoMmO"
      },
      "source": [
        "## Install Huggingface Library\n",
        "\n",
        "These should have been installed during your environment set-up; you only need to run these cells in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxskHmKgoJCP",
        "outputId": "4ecb81dc-2be2-4416-98e2-de7215a0f3d4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=9af3a36ceee77394672eb57f65c79e678b85f867bed61d8f68dbba52f6535b50\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lww2Jo_TGiXx"
      },
      "source": [
        "# Data directories and file paths\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7d6Ny-lGef1"
      },
      "source": [
        "train_file = \"image_labels_impression_frontal_train.jsonl\" \n",
        "val_file = \"image_labels_impression_frontal_val.jsonl\" \n",
        "test_file = \"image_labels_impression_frontal_test.jsonl\" "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rodBL17AuSJ6"
      },
      "source": [
        "## Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNP7dJV2hTKG"
      },
      "source": [
        "from textBert_utils import set_seed\n",
        "from MMBT.image import ImageEncoderDenseNet\n",
        "from MMBT.mmbt_config import MMBTConfig\n",
        "from MMBT.mmbt import MMBTForClassification"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqM0DScsmCnX"
      },
      "source": [
        "from MMBT.mmbt_utils import JsonlDataset, get_image_transforms, get_labels, load_examples, collate_fn"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wUXVNbSoBVo"
      },
      "source": [
        "import argparse"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th_vPKXcpn4R"
      },
      "source": [
        "import glob\n",
        "import logging\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWUF76E4y1CC"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfYeENaFDbmO"
      },
      "source": [
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWgdU7lBnyFd"
      },
      "source": [
        "# Set-up Experiment Hyperparameters and Arguments\n",
        "\n",
        "Specify the training, validation, and test files to run the experiment on. The default here is running the model on 'impression' texts.  \n",
        "\n",
        "To re-make the training, validation, and test data, please refer to the information in the **data/** directory.  \n",
        "\n",
        "Change the default values in the parser.add_argument function for the hyperparameters that you want to specify in the following cell or use the default option.  \n",
        "\n",
        "For multiple experiment runs, please make sure to change the `output_dir` argument so that new results don't overwrit existing ones.\n",
        "\n",
        "The arguments specified here are the same as in the `run_mmimdb.py` file \n",
        "in the [Huggingface example implementation of MMBT.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urly6ofboEmU"
      },
      "source": [
        "parser = argparse.ArgumentParser(f'Project Hyperparameters and Other Configurations Argument Parser')\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Required parameters\n",
        "parser.add_argument(\n",
        "    \"--data_dir\",\n",
        "    default=\"data/json\",\n",
        "    type=str,\n",
        "    help=\"The input data dir. Should contain the .jsonl files.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--model_name\",\n",
        "    default=\"bert-base-uncased\",\n",
        "    type=str,\n",
        "    help=\"model identifier from huggingface.co/models\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--output_dir\",\n",
        "    default=\"mmbt_output_impression\",\n",
        "    type=str,\n",
        "    help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        ")\n",
        "\n",
        "    \n",
        "parser.add_argument(\n",
        "    \"--config_name\", default=\"bert-base-uncased\", type=str, help=\"Pretrained config name if not the same as model_name\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--tokenizer_name\",\n",
        "    default=\"bert-base-uncased\",\n",
        "    type=str,\n",
        "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--train_batch_size\", default=32, type=int, help=\"Batch size for training.\")\n",
        "parser.add_argument(\n",
        "    \"--eval_batch_size\", default=32, type=int, help=\"Batch size for evaluation.\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--max_seq_length\",\n",
        "    default=256,\n",
        "    type=int,\n",
        "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "    \"than this will be truncated, sequences shorter will be padded.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--num_image_embeds\", default=3, type=int, help=\"Number of Image Embeddings from the Image Encoder\"\n",
        ")\n",
        "parser.add_argument(\"--do_train\", default=True, type=bool, help=\"Whether to run training.\")\n",
        "parser.add_argument(\"--do_eval\", default=True, type=bool, help=\"Whether to run eval on the dev set.\")\n",
        "parser.add_argument(\n",
        "    \"--evaluate_during_training\", default=True, type=bool, help=\"Rul evaluation during training at each logging step.\"\n",
        ")\n",
        "\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--gradient_accumulation_steps\",\n",
        "    type=int,\n",
        "    default=1,\n",
        "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        ")\n",
        "parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "parser.add_argument(\"--weight_decay\", default=0.1, type=float, help=\"Weight deay if we apply some.\")\n",
        "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "parser.add_argument(\n",
        "    \"--num_train_epochs\", default=4.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        ")\n",
        "parser.add_argument(\"--patience\", default=5, type=int, help=\"Patience for Early Stopping.\")\n",
        "parser.add_argument(\n",
        "    \"--max_steps\",\n",
        "    default=-1,\n",
        "    type=int,\n",
        "    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        ")\n",
        "parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "parser.add_argument(\"--logging_steps\", type=int, default=25, help=\"Log every X updates steps.\")\n",
        "parser.add_argument(\"--save_steps\", type=int, default=25, help=\"Save checkpoint every X updates steps.\")\n",
        "parser.add_argument(\n",
        "    \"--eval_all_checkpoints\",\n",
        "    default=True, type=bool,\n",
        "    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--num_workers\", type=int, default=8, help=\"number of worker threads for dataloading\")\n",
        "\n",
        "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "# Setup CUDA, GPU & distributed training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.n_gpu = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
        "args.device = device"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBKm89HqqqO6"
      },
      "source": [
        "# Setup Train/Val/Test filenames\n",
        "args.train_file = train_file\n",
        "args.val_file = val_file\n",
        "args.test_file = test_file"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKOToFXcKxs1"
      },
      "source": [
        "## Showing a sample from JsonDataset\n",
        "i.e. calling \"\\_\\_getitem\\_\\_\"\n",
        "\n",
        "Note:   \n",
        "image_end_token is the BERT token id for [SEP].   \n",
        "image_start_token is the BERT token id for [CLS]. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_cC7-CQFKyP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "8bbc787eca2344ba9e86f2f2c08da546",
            "0fde5333d14f47039f0b7f498abe2d4d",
            "c944a250a63840a1bceb7a5737e60f44",
            "f33f21d6394c47bc98bcaabb7b5ff841",
            "f757bdb31d9a4411947ef247e51e8a37",
            "6fa645744d444308b76e2910abfe3c7c",
            "362b061f765845478e192e298d146b5e",
            "9acb0b1810c24a3a95f40a4e28236a15",
            "2eb2f22ab5ee484fb3ae55f7c8a5539d",
            "6f44a07efefa42eeb9da885bd28e0867",
            "a2720413f26c4423afe7bb76fe6b81d7",
            "918ac453c8684157b5acac8ee2ed3b5f",
            "b1ae447a85c645a58fece46bab169764",
            "1daa1a89fb46429194709962710d9b0c",
            "7922eee3e3b94f8d96ec8012351bcfd7",
            "b270d59df2db4c3aa51f5d6bec8f2a11",
            "76f1ce7ff972417fa783bb47bcbea288",
            "c3cf4c515055441ca3cf88e508961e19",
            "a5af2ccd2c6446cd8f380513acf8f8b9",
            "b77648d304c74c50a2b5b24c859c7245",
            "15ed30801e884c4886988da0b2febd24",
            "0eb6a99fd54546a18bb501c0339e4024",
            "c67a7ea396144bf1b70f69ede7a804bd",
            "f3caa2641b954ee8bb1b63ebaadde2d8"
          ]
        },
        "outputId": "a258e7f7-c43d-4ce6-bbf7-9d88220d6d76"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name,\n",
        "        do_lower_case=True,\n",
        "        cache_dir=None,\n",
        "    )\n",
        "train_dataset = load_examples(tokenizer, args)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bbc787eca2344ba9e86f2f2c08da546",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2eb2f22ab5ee484fb3ae55f7c8a5539d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76f1ce7ff972417fa783bb47bcbea288",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S80TAkjvJ9ZC",
        "outputId": "e7c00140-f037-449e-9970-f793c76d9a4f"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[ 0.4679,  0.4166,  0.3481,  ..., -0.7822, -0.7822, -0.7993],\n",
              "          [ 0.4851,  0.5022,  0.5364,  ..., -0.5938, -0.5938, -0.6452],\n",
              "          [ 0.4166,  0.3823,  0.4337,  ..., -0.4226, -0.4226, -0.4568],\n",
              "          ...,\n",
              "          [ 1.8722,  1.9064,  1.9235,  ...,  0.7248,  0.6734,  0.6221],\n",
              "          [ 1.8208,  1.8550,  1.9064,  ...,  0.7248,  0.6734,  0.6392],\n",
              "          [ 1.7865,  1.8208,  1.8379,  ...,  0.7077,  0.6906,  0.6563]],\n",
              " \n",
              "         [[ 0.6078,  0.5553,  0.4853,  ..., -0.6702, -0.6702, -0.6877],\n",
              "          [ 0.6254,  0.6429,  0.6779,  ..., -0.4776, -0.4776, -0.5301],\n",
              "          [ 0.5553,  0.5203,  0.5728,  ..., -0.3025, -0.3025, -0.3375],\n",
              "          ...,\n",
              "          [ 2.0434,  2.0784,  2.0959,  ...,  0.8704,  0.8179,  0.7654],\n",
              "          [ 1.9909,  2.0259,  2.0784,  ...,  0.8704,  0.8179,  0.7829],\n",
              "          [ 1.9559,  1.9909,  2.0084,  ...,  0.8529,  0.8354,  0.8004]],\n",
              " \n",
              "         [[ 0.8274,  0.7751,  0.7054,  ..., -0.4450, -0.4450, -0.4624],\n",
              "          [ 0.8448,  0.8622,  0.8971,  ..., -0.2532, -0.2532, -0.3055],\n",
              "          [ 0.7751,  0.7402,  0.7925,  ..., -0.0790, -0.0790, -0.1138],\n",
              "          ...,\n",
              "          [ 2.2566,  2.2914,  2.3088,  ...,  1.0888,  1.0365,  0.9842],\n",
              "          [ 2.2043,  2.2391,  2.2914,  ...,  1.0888,  1.0365,  1.0017],\n",
              "          [ 2.1694,  2.2043,  2.2217,  ...,  1.0714,  1.0539,  1.0191]]]),\n",
              " 'image_end_token': tensor(102),\n",
              " 'image_start_token': tensor(101),\n",
              " 'label': tensor([0]),\n",
              " 'sentence': tensor([ 2053, 11325,  4003,  3695, 14289, 13728,  7856,  2854,  9556,  1012])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_qY3Xe7Owyq"
      },
      "source": [
        "\n",
        "### Training and Evaluating Functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0es3QJnQY7V"
      },
      "source": [
        "def train(args, train_dataset, model, tokenizer):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    \n",
        "    tb_writer = SummaryWriter()\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=args.train_batch_size,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    \n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\n",
        "        \"  Total train batch size = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    best_accuracy, n_no_improve = 0, 0\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Training Batch Iteration\")\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            # model.train()\n",
        "            # each sample in batch is a tuple\n",
        "            # batch is the return of the collate_fn function\n",
        "            # see function definition for data tuple order\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            labels = batch[5]\n",
        "            input_ids = batch[0]\n",
        "            input_modal = batch[2]\n",
        "            attention_mask = batch[1]\n",
        "            modal_start_tokens = batch[3]\n",
        "            modal_end_tokens = batch[4]\n",
        "\n",
        "            #inputs = {\n",
        "            #    \"input_ids\": batch[0],\n",
        "            #    \"input_modal\": batch[2],\n",
        "            #    \"attention_mask\": batch[1],\n",
        "            #    \"modal_start_tokens\": batch[3],\n",
        "            #    \"modal_end_tokens\": batch[4],\n",
        "            #    \"labels\": batch[5]\n",
        "            #}\n",
        "\n",
        "            outputs = model(\n",
        "                input_modal,\n",
        "                input_ids=input_ids,\n",
        "                modal_start_tokens=modal_start_tokens,\n",
        "                modal_end_tokens=modal_end_tokens,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=None,\n",
        "                modal_token_type_ids=None,\n",
        "                position_ids=None,\n",
        "                modal_position_ids=None,\n",
        "                head_mask=None,\n",
        "                inputs_embeds=None,\n",
        "                labels=labels,\n",
        "                return_dict=True\n",
        "            )\n",
        "            #logits = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "            #loss = criterion(logits, labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            \n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    logs = {}\n",
        "                    if args.evaluate_during_training:  \n",
        "                        # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            eval_key = \"eval_{}\".format(key)\n",
        "                            logs[eval_key] = value\n",
        "\n",
        "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
        "                    learning_rate_scalar = scheduler.get_last_lr()[0]\n",
        "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
        "                    logs[\"loss\"] = loss_scalar\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                    for key, value in logs.items():\n",
        "                        tb_writer.add_scalar(key, value, global_step)\n",
        "                    print(json.dumps({**logs, **{\"step\": global_step}}))\n",
        "\n",
        "                if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    torch.save(model_to_save.state_dict(), os.path.join(output_dir, WEIGHTS_NAME))\n",
        "                    # uncomment below to be able to save args\n",
        "                    # torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "\n",
        "        results = evaluate(args, model, tokenizer)\n",
        "        if results[\"accuracy\"] > best_accuracy:\n",
        "            best_accuracy = results[\"accuracy\"]\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "\n",
        "        if n_no_improve > args.patience:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwg0asA2Zm6P"
      },
      "source": [
        "def evaluate(args, model, tokenizer, evaluate=True, test=False, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_output_dir = args.output_dir\n",
        "    eval_dataset = load_examples(tokenizer, args, evaluate=evaluate, test=test)\n",
        "\n",
        "    if not os.path.exists(eval_output_dir):\n",
        "        os.makedirs(eval_output_dir)\n",
        "\n",
        "    # Note that DistributedSampler samples randomly\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = []\n",
        "    out_label_ids = []\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            labels = batch[5]\n",
        "            input_ids = batch[0]\n",
        "            input_modal = batch[2]\n",
        "            attention_mask = batch[1]\n",
        "            modal_start_tokens = batch[3]\n",
        "            modal_end_tokens = batch[4]\n",
        "            \n",
        "            outputs = model(\n",
        "                input_modal,\n",
        "                input_ids=input_ids,\n",
        "                modal_start_tokens=modal_start_tokens,\n",
        "                modal_end_tokens=modal_end_tokens,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=None,\n",
        "                modal_token_type_ids=None,\n",
        "                position_ids=None,\n",
        "                modal_position_ids=None,\n",
        "                head_mask=None,\n",
        "                inputs_embeds=None,\n",
        "                labels=labels,\n",
        "                return_dict=True\n",
        "            )\n",
        "            #logits = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "            #tmp_eval_loss = criterion(logits, labels)\n",
        "            tmp_eval_loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        # Move logits and labels to CPU            \n",
        "        pred = torch.nn.functional.softmax(logits, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "        out_label_id = labels.detach().cpu().numpy()\n",
        "        preds.append(pred)\n",
        "        out_label_ids.append(out_label_id)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    out_label_ids = [l for sl in out_label_ids for l in sl]\n",
        "\n",
        "    result = {\n",
        "        \"loss\": eval_loss,\n",
        "        \"accuracy\": accuracy_score(out_label_ids, preds)\n",
        "    }\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return result\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mrKUcxxcbs3"
      },
      "source": [
        "## Training MMBT Model \n",
        "\n",
        "Set up logging and the MMBT Model. Similar to the text-only model, check points \n",
        "are saved during a similar customizable interval.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3-ZxIuRcdfO"
      },
      "source": [
        "# Setup logging\n",
        "logger = logging.getLogger(__name__)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "                    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "                    filename=os.path.join(args.output_dir, f\"{os.path.splitext(args.train_file)[0]}_logging.txt\"),\n",
        "                    level=logging.INFO)\n",
        "logger.warning(\"device: %s, n_gpu: %s\",\n",
        "        args.device,\n",
        "        args.n_gpu\n",
        ")\n",
        "# Set the verbosity to info of the Transformers logger (on main process only):\n",
        "\n",
        "# Set seed\n",
        "set_seed(args)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "600aa6ce4b344deb9552f7d4fc9b3435",
            "321fa705c8c641b783af0126f9972847",
            "bf0cd0d3375b4e7b8268a9e24e535662",
            "745db171650246e4a042877786e4a4f3",
            "b9f99c6855ed4dfeb5c3e2bcfe6bf99e",
            "344d87921ba8483c84ddb55c060f4b75",
            "4936ef401a27409296544986eead1ae8",
            "1c2762b75f8d4b7fad14830761a15db2"
          ]
        },
        "id": "ZDgzsLlcc-Uk",
        "outputId": "1eb01b49-a341-4e16-ff0d-49e05528d13c"
      },
      "source": [
        "# Setup model\n",
        "labels = get_labels()\n",
        "num_labels = len(labels)\n",
        "transformer_config = AutoConfig.from_pretrained(args.config_name if args.config_name else args.model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name,\n",
        "        do_lower_case=True,\n",
        "        cache_dir=None,\n",
        "    )\n",
        "transformer = AutoModel.from_pretrained(args.model_name, config=transformer_config, cache_dir=None)\n",
        "img_encoder = ImageEncoderDenseNet(num_image_embeds=args.num_image_embeds)\n",
        "multimodal_config = MMBTConfig(transformer, img_encoder, num_labels=num_labels, modal_hidden_size=1024)\n",
        "model = MMBTForClassification(transformer_config, multimodal_config)\n",
        "\n",
        "model.to(args.device)\n",
        "\n",
        "logger.info(f\"Training/evaluation parameters: {args}\")\n",
        "\n",
        "# Training\n",
        "if args.do_train:\n",
        "    train_dataset = load_examples(tokenizer, args)\n",
        "    # criterion = nn.CrossEntropyLoss\n",
        "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "    # They can then be reloaded using `from_pretrained()`\n",
        "    model_to_save = (model.module if hasattr(model, \"module\") else model)  # Take care of distributed/parallel training\n",
        "    torch.save(model_to_save.state_dict(), os.path.join(args.output_dir, WEIGHTS_NAME))\n",
        "    tokenizer.save_pretrained(args.output_dir)\n",
        "    transformer_config.save_pretrained(args.output_dir)\n",
        "    # Good practice: save your training arguments together with the trained model\n",
        "    torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "    # Load a trained model and vocabulary that you have fine-tuned\n",
        "    model = MMBTForClassification(transformer_config, multimodal_config)\n",
        "    model.load_state_dict(torch.load(os.path.join(args.output_dir, WEIGHTS_NAME)))\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "    model.to(args.device)\n",
        "logger.info(\"***** Training Finished *****\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "600aa6ce4b344deb9552f7d4fc9b3435",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "Training Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
            "Training Batch Iteration:   2%|▏         | 1/61 [00:18<18:57, 18.96s/it]\u001b[A\n",
            "Training Batch Iteration:   3%|▎         | 2/61 [00:32<17:06, 17.39s/it]\u001b[A\n",
            "Training Batch Iteration:   5%|▍         | 3/61 [00:47<15:55, 16.47s/it]\u001b[A\n",
            "Training Batch Iteration:   7%|▋         | 4/61 [01:01<15:04, 15.88s/it]\u001b[A\n",
            "Training Batch Iteration:   8%|▊         | 5/61 [01:15<14:18, 15.33s/it]\u001b[A\n",
            "Training Batch Iteration:  10%|▉         | 6/61 [01:29<13:43, 14.97s/it]\u001b[A\n",
            "Training Batch Iteration:  11%|█▏        | 7/61 [01:43<13:03, 14.51s/it]\u001b[A\n",
            "Training Batch Iteration:  13%|█▎        | 8/61 [01:57<12:40, 14.35s/it]\u001b[A\n",
            "Training Batch Iteration:  15%|█▍        | 9/61 [02:10<12:18, 14.21s/it]\u001b[A\n",
            "Training Batch Iteration:  16%|█▋        | 10/61 [02:24<11:54, 14.01s/it]\u001b[A\n",
            "Training Batch Iteration:  18%|█▊        | 11/61 [02:38<11:38, 13.98s/it]\u001b[A\n",
            "Training Batch Iteration:  20%|█▉        | 12/61 [02:51<11:17, 13.82s/it]\u001b[A\n",
            "Training Batch Iteration:  21%|██▏       | 13/61 [03:05<11:03, 13.82s/it]\u001b[A\n",
            "Training Batch Iteration:  23%|██▎       | 14/61 [03:18<10:37, 13.56s/it]\u001b[A\n",
            "Training Batch Iteration:  25%|██▍       | 15/61 [03:32<10:22, 13.53s/it]\u001b[A\n",
            "Training Batch Iteration:  26%|██▌       | 16/61 [03:45<10:07, 13.50s/it]\u001b[A\n",
            "Training Batch Iteration:  28%|██▊       | 17/61 [03:58<09:47, 13.36s/it]\u001b[A\n",
            "Training Batch Iteration:  30%|██▉       | 18/61 [04:12<09:39, 13.47s/it]\u001b[A\n",
            "Training Batch Iteration:  31%|███       | 19/61 [04:25<09:20, 13.34s/it]\u001b[A\n",
            "Training Batch Iteration:  33%|███▎      | 20/61 [04:38<08:59, 13.16s/it]\u001b[A\n",
            "Training Batch Iteration:  34%|███▍      | 21/61 [04:51<08:50, 13.27s/it]\u001b[A\n",
            "Training Batch Iteration:  36%|███▌      | 22/61 [05:04<08:38, 13.29s/it]\u001b[A\n",
            "Training Batch Iteration:  38%|███▊      | 23/61 [05:18<08:28, 13.39s/it]\u001b[A\n",
            "Training Batch Iteration:  39%|███▉      | 24/61 [05:31<08:08, 13.19s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:12<04:04, 12.24s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:25<03:57, 12.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:37<03:44, 12.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:50<03:35, 12.70s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [01:03<03:22, 12.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [01:16<03:09, 12.61s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [01:28<02:54, 12.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [01:41<02:44, 12.68s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [01:53<02:30, 12.58s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [02:07<02:21, 12.85s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [02:19<02:06, 12.69s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [02:31<01:53, 12.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [02:44<01:39, 12.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [02:56<01:27, 12.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [03:09<01:16, 12.71s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [03:22<01:03, 12.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [03:34<00:50, 12.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [03:46<00:37, 12.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [03:59<00:24, 12.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [04:12<00:12, 12.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [04:15<00:00, 12.16s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.3071372416757402, \"eval_accuracy\": 0.8952234206471494, \"learning_rate\": 4.487704918032787e-05, \"loss\": 0.46950038194656374, \"step\": 25}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  41%|████      | 25/61 [10:02<54:19, 90.55s/it]\u001b[A\n",
            "Training Batch Iteration:  43%|████▎     | 26/61 [10:14<39:09, 67.11s/it]\u001b[A\n",
            "Training Batch Iteration:  44%|████▍     | 27/61 [10:27<28:42, 50.65s/it]\u001b[A\n",
            "Training Batch Iteration:  46%|████▌     | 28/61 [10:39<21:33, 39.21s/it]\u001b[A\n",
            "Training Batch Iteration:  48%|████▊     | 29/61 [10:52<16:44, 31.39s/it]\u001b[A\n",
            "Training Batch Iteration:  49%|████▉     | 30/61 [11:05<13:16, 25.68s/it]\u001b[A\n",
            "Training Batch Iteration:  51%|█████     | 31/61 [11:18<10:57, 21.93s/it]\u001b[A\n",
            "Training Batch Iteration:  52%|█████▏    | 32/61 [11:31<09:17, 19.21s/it]\u001b[A\n",
            "Training Batch Iteration:  54%|█████▍    | 33/61 [11:43<08:03, 17.26s/it]\u001b[A\n",
            "Training Batch Iteration:  56%|█████▌    | 34/61 [11:56<07:06, 15.81s/it]\u001b[A\n",
            "Training Batch Iteration:  57%|█████▋    | 35/61 [12:08<06:26, 14.86s/it]\u001b[A\n",
            "Training Batch Iteration:  59%|█████▉    | 36/61 [12:21<05:58, 14.33s/it]\u001b[A\n",
            "Training Batch Iteration:  61%|██████    | 37/61 [12:34<05:30, 13.75s/it]\u001b[A\n",
            "Training Batch Iteration:  62%|██████▏   | 38/61 [12:46<05:07, 13.39s/it]\u001b[A\n",
            "Training Batch Iteration:  64%|██████▍   | 39/61 [12:59<04:48, 13.13s/it]\u001b[A\n",
            "Training Batch Iteration:  66%|██████▌   | 40/61 [13:11<04:31, 12.91s/it]\u001b[A\n",
            "Training Batch Iteration:  67%|██████▋   | 41/61 [13:24<04:15, 12.77s/it]\u001b[A\n",
            "Training Batch Iteration:  69%|██████▉   | 42/61 [13:36<04:02, 12.75s/it]\u001b[A\n",
            "Training Batch Iteration:  70%|███████   | 43/61 [13:49<03:49, 12.73s/it]\u001b[A\n",
            "Training Batch Iteration:  72%|███████▏  | 44/61 [14:03<03:40, 12.94s/it]\u001b[A\n",
            "Training Batch Iteration:  74%|███████▍  | 45/61 [14:16<03:27, 12.99s/it]\u001b[A\n",
            "Training Batch Iteration:  75%|███████▌  | 46/61 [14:28<03:12, 12.84s/it]\u001b[A\n",
            "Training Batch Iteration:  77%|███████▋  | 47/61 [14:41<02:58, 12.72s/it]\u001b[A\n",
            "Training Batch Iteration:  79%|███████▊  | 48/61 [14:53<02:43, 12.55s/it]\u001b[A\n",
            "Training Batch Iteration:  80%|████████  | 49/61 [15:06<02:33, 12.78s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  2.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:06,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.1675085269269489, \"eval_accuracy\": 0.9414483821263482, \"learning_rate\": 3.975409836065574e-05, \"loss\": 0.20768402725458146, \"step\": 50}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  82%|████████▏ | 50/61 [15:31<03:00, 16.38s/it]\u001b[A\n",
            "Training Batch Iteration:  84%|████████▎ | 51/61 [15:44<02:33, 15.39s/it]\u001b[A\n",
            "Training Batch Iteration:  85%|████████▌ | 52/61 [15:56<02:09, 14.43s/it]\u001b[A\n",
            "Training Batch Iteration:  87%|████████▋ | 53/61 [16:09<01:51, 13.92s/it]\u001b[A\n",
            "Training Batch Iteration:  89%|████████▊ | 54/61 [16:22<01:35, 13.67s/it]\u001b[A\n",
            "Training Batch Iteration:  90%|█████████ | 55/61 [16:35<01:20, 13.39s/it]\u001b[A\n",
            "Training Batch Iteration:  92%|█████████▏| 56/61 [16:48<01:07, 13.47s/it]\u001b[A\n",
            "Training Batch Iteration:  93%|█████████▎| 57/61 [17:00<00:52, 13.05s/it]\u001b[A\n",
            "Training Batch Iteration:  95%|█████████▌| 58/61 [17:13<00:39, 13.03s/it]\u001b[A\n",
            "Training Batch Iteration:  97%|█████████▋| 59/61 [17:25<00:25, 12.72s/it]\u001b[A\n",
            "Training Batch Iteration:  98%|█████████▊| 60/61 [17:38<00:12, 12.78s/it]\u001b[A\n",
            "Training Batch Iteration: 100%|██████████| 61/61 [17:50<00:00, 17.54s/it]\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.93it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.89it/s]\u001b[A\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.92it/s]\u001b[A\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.96it/s]\u001b[A\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.95it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.80it/s]\u001b[A\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.86it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.81it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.80it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.83it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.93it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.91it/s]\u001b[A\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.88it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.87it/s]\u001b[A\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.85it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.93it/s]\n",
            "Epoch:  25%|██▌       | 1/4 [18:01<54:03, 1081.05s/it]\n",
            "Training Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
            "Training Batch Iteration:   2%|▏         | 1/61 [00:00<00:58,  1.02it/s]\u001b[A\n",
            "Training Batch Iteration:   3%|▎         | 2/61 [00:02<00:59,  1.01s/it]\u001b[A\n",
            "Training Batch Iteration:   5%|▍         | 3/61 [00:03<00:58,  1.02s/it]\u001b[A\n",
            "Training Batch Iteration:   7%|▋         | 4/61 [00:04<01:01,  1.07s/it]\u001b[A\n",
            "Training Batch Iteration:   8%|▊         | 5/61 [00:05<00:57,  1.03s/it]\u001b[A\n",
            "Training Batch Iteration:  10%|▉         | 6/61 [00:06<00:56,  1.03s/it]\u001b[A\n",
            "Training Batch Iteration:  11%|█▏        | 7/61 [00:07<00:54,  1.00s/it]\u001b[A\n",
            "Training Batch Iteration:  13%|█▎        | 8/61 [00:08<00:54,  1.03s/it]\u001b[A\n",
            "Training Batch Iteration:  15%|█▍        | 9/61 [00:09<00:53,  1.03s/it]\u001b[A\n",
            "Training Batch Iteration:  16%|█▋        | 10/61 [00:10<00:53,  1.05s/it]\u001b[A\n",
            "Training Batch Iteration:  18%|█▊        | 11/61 [00:11<00:51,  1.02s/it]\u001b[A\n",
            "Training Batch Iteration:  20%|█▉        | 12/61 [00:12<00:50,  1.03s/it]\u001b[A\n",
            "Training Batch Iteration:  21%|██▏       | 13/61 [00:13<00:50,  1.05s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.17225747690757826, \"eval_accuracy\": 0.963020030816641, \"learning_rate\": 3.463114754098361e-05, \"loss\": 0.1314369172602892, \"step\": 75}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  23%|██▎       | 14/61 [00:27<03:53,  4.98s/it]\u001b[A\n",
            "Training Batch Iteration:  25%|██▍       | 15/61 [00:28<02:56,  3.84s/it]\u001b[A\n",
            "Training Batch Iteration:  26%|██▌       | 16/61 [00:29<02:14,  2.99s/it]\u001b[A\n",
            "Training Batch Iteration:  28%|██▊       | 17/61 [00:31<01:48,  2.46s/it]\u001b[A\n",
            "Training Batch Iteration:  30%|██▉       | 18/61 [00:32<01:29,  2.09s/it]\u001b[A\n",
            "Training Batch Iteration:  31%|███       | 19/61 [00:33<01:18,  1.86s/it]\u001b[A\n",
            "Training Batch Iteration:  33%|███▎      | 20/61 [00:35<01:14,  1.82s/it]\u001b[A\n",
            "Training Batch Iteration:  34%|███▍      | 21/61 [00:36<01:06,  1.66s/it]\u001b[A\n",
            "Training Batch Iteration:  36%|███▌      | 22/61 [00:38<01:08,  1.76s/it]\u001b[A\n",
            "Training Batch Iteration:  38%|███▊      | 23/61 [00:39<01:01,  1.62s/it]\u001b[A\n",
            "Training Batch Iteration:  39%|███▉      | 24/61 [00:40<00:53,  1.44s/it]\u001b[A\n",
            "Training Batch Iteration:  41%|████      | 25/61 [00:42<00:49,  1.39s/it]\u001b[A\n",
            "Training Batch Iteration:  43%|████▎     | 26/61 [00:43<00:44,  1.26s/it]\u001b[A\n",
            "Training Batch Iteration:  44%|████▍     | 27/61 [00:44<00:42,  1.24s/it]\u001b[A\n",
            "Training Batch Iteration:  46%|████▌     | 28/61 [00:45<00:40,  1.22s/it]\u001b[A\n",
            "Training Batch Iteration:  48%|████▊     | 29/61 [00:46<00:37,  1.19s/it]\u001b[A\n",
            "Training Batch Iteration:  49%|████▉     | 30/61 [00:47<00:37,  1.20s/it]\u001b[A\n",
            "Training Batch Iteration:  51%|█████     | 31/61 [00:48<00:35,  1.17s/it]\u001b[A\n",
            "Training Batch Iteration:  52%|█████▏    | 32/61 [00:50<00:35,  1.21s/it]\u001b[A\n",
            "Training Batch Iteration:  54%|█████▍    | 33/61 [00:51<00:32,  1.17s/it]\u001b[A\n",
            "Training Batch Iteration:  56%|█████▌    | 34/61 [00:52<00:30,  1.12s/it]\u001b[A\n",
            "Training Batch Iteration:  57%|█████▋    | 35/61 [00:53<00:27,  1.06s/it]\u001b[A\n",
            "Training Batch Iteration:  59%|█████▉    | 36/61 [00:54<00:26,  1.08s/it]\u001b[A\n",
            "Training Batch Iteration:  61%|██████    | 37/61 [00:55<00:25,  1.08s/it]\u001b[A\n",
            "Training Batch Iteration:  62%|██████▏   | 38/61 [00:56<00:25,  1.12s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:09,  2.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  2.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:07<00:03,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.13353006976346174, \"eval_accuracy\": 0.9583975346687211, \"learning_rate\": 2.9508196721311478e-05, \"loss\": 0.12748133765533567, \"step\": 100}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  64%|██████▍   | 39/61 [01:10<01:50,  5.03s/it]\u001b[A\n",
            "Training Batch Iteration:  66%|██████▌   | 40/61 [01:12<01:21,  3.87s/it]\u001b[A\n",
            "Training Batch Iteration:  67%|██████▋   | 41/61 [01:13<01:00,  3.03s/it]\u001b[A\n",
            "Training Batch Iteration:  69%|██████▉   | 42/61 [01:14<00:47,  2.51s/it]\u001b[A\n",
            "Training Batch Iteration:  70%|███████   | 43/61 [01:15<00:37,  2.07s/it]\u001b[A\n",
            "Training Batch Iteration:  72%|███████▏  | 44/61 [01:16<00:30,  1.81s/it]\u001b[A\n",
            "Training Batch Iteration:  74%|███████▍  | 45/61 [01:17<00:26,  1.63s/it]\u001b[A\n",
            "Training Batch Iteration:  75%|███████▌  | 46/61 [01:19<00:22,  1.52s/it]\u001b[A\n",
            "Training Batch Iteration:  77%|███████▋  | 47/61 [01:20<00:20,  1.44s/it]\u001b[A\n",
            "Training Batch Iteration:  79%|███████▊  | 48/61 [01:21<00:17,  1.34s/it]\u001b[A\n",
            "Training Batch Iteration:  80%|████████  | 49/61 [01:22<00:14,  1.25s/it]\u001b[A\n",
            "Training Batch Iteration:  82%|████████▏ | 50/61 [01:23<00:13,  1.21s/it]\u001b[A\n",
            "Training Batch Iteration:  84%|████████▎ | 51/61 [01:24<00:11,  1.17s/it]\u001b[A\n",
            "Training Batch Iteration:  85%|████████▌ | 52/61 [01:25<00:10,  1.20s/it]\u001b[A\n",
            "Training Batch Iteration:  87%|████████▋ | 53/61 [01:27<00:09,  1.22s/it]\u001b[A\n",
            "Training Batch Iteration:  89%|████████▊ | 54/61 [01:28<00:08,  1.24s/it]\u001b[A\n",
            "Training Batch Iteration:  90%|█████████ | 55/61 [01:29<00:07,  1.21s/it]\u001b[A\n",
            "Training Batch Iteration:  92%|█████████▏| 56/61 [01:31<00:06,  1.26s/it]\u001b[A\n",
            "Training Batch Iteration:  93%|█████████▎| 57/61 [01:32<00:04,  1.24s/it]\u001b[A\n",
            "Training Batch Iteration:  95%|█████████▌| 58/61 [01:33<00:03,  1.22s/it]\u001b[A\n",
            "Training Batch Iteration:  97%|█████████▋| 59/61 [01:34<00:02,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:  98%|█████████▊| 60/61 [01:35<00:01,  1.21s/it]\u001b[A\n",
            "Training Batch Iteration: 100%|██████████| 61/61 [01:36<00:00,  1.59s/it]\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.86it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:10,  1.85it/s]\u001b[A\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.89it/s]\u001b[A\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.94it/s]\u001b[A\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.94it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.81it/s]\u001b[A\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.87it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.80it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.79it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.83it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.93it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.92it/s]\u001b[A\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.84it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.86it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.89it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.90it/s]\u001b[A\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.89it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.87it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.94it/s]\n",
            "Epoch:  50%|█████     | 2/4 [19:48<26:18, 789.01s/it] \n",
            "Training Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
            "Training Batch Iteration:   2%|▏         | 1/61 [00:01<01:11,  1.19s/it]\u001b[A\n",
            "Training Batch Iteration:   3%|▎         | 2/61 [00:02<01:08,  1.16s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:06,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.16078567731061152, \"eval_accuracy\": 0.9583975346687211, \"learning_rate\": 2.4385245901639343e-05, \"loss\": 0.07961560974828899, \"step\": 125}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:   5%|▍         | 3/61 [00:17<05:08,  5.33s/it]\u001b[A\n",
            "Training Batch Iteration:   7%|▋         | 4/61 [00:18<03:52,  4.08s/it]\u001b[A\n",
            "Training Batch Iteration:   8%|▊         | 5/61 [00:19<02:56,  3.14s/it]\u001b[A\n",
            "Training Batch Iteration:  10%|▉         | 6/61 [00:20<02:20,  2.55s/it]\u001b[A\n",
            "Training Batch Iteration:  11%|█▏        | 7/61 [00:21<01:54,  2.12s/it]\u001b[A\n",
            "Training Batch Iteration:  13%|█▎        | 8/61 [00:22<01:36,  1.82s/it]\u001b[A\n",
            "Training Batch Iteration:  15%|█▍        | 9/61 [00:23<01:23,  1.60s/it]\u001b[A\n",
            "Training Batch Iteration:  16%|█▋        | 10/61 [00:25<01:14,  1.46s/it]\u001b[A\n",
            "Training Batch Iteration:  18%|█▊        | 11/61 [00:26<01:08,  1.37s/it]\u001b[A\n",
            "Training Batch Iteration:  20%|█▉        | 12/61 [00:27<01:05,  1.33s/it]\u001b[A\n",
            "Training Batch Iteration:  21%|██▏       | 13/61 [00:28<01:02,  1.31s/it]\u001b[A\n",
            "Training Batch Iteration:  23%|██▎       | 14/61 [00:30<01:02,  1.33s/it]\u001b[A\n",
            "Training Batch Iteration:  25%|██▍       | 15/61 [00:31<01:00,  1.31s/it]\u001b[A\n",
            "Training Batch Iteration:  26%|██▌       | 16/61 [00:32<00:56,  1.25s/it]\u001b[A\n",
            "Training Batch Iteration:  28%|██▊       | 17/61 [00:33<00:52,  1.20s/it]\u001b[A\n",
            "Training Batch Iteration:  30%|██▉       | 18/61 [00:34<00:50,  1.16s/it]\u001b[A\n",
            "Training Batch Iteration:  31%|███       | 19/61 [00:35<00:46,  1.11s/it]\u001b[A\n",
            "Training Batch Iteration:  33%|███▎      | 20/61 [00:36<00:47,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:  34%|███▍      | 21/61 [00:37<00:44,  1.11s/it]\u001b[A\n",
            "Training Batch Iteration:  36%|███▌      | 22/61 [00:38<00:43,  1.11s/it]\u001b[A\n",
            "Training Batch Iteration:  38%|███▊      | 23/61 [00:39<00:39,  1.05s/it]\u001b[A\n",
            "Training Batch Iteration:  39%|███▉      | 24/61 [00:41<00:40,  1.09s/it]\u001b[A\n",
            "Training Batch Iteration:  41%|████      | 25/61 [00:42<00:38,  1.06s/it]\u001b[A\n",
            "Training Batch Iteration:  43%|████▎     | 26/61 [00:43<00:44,  1.26s/it]\u001b[A\n",
            "Training Batch Iteration:  44%|████▍     | 27/61 [00:44<00:40,  1.18s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:09,  2.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  2.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:07<00:03,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:08<00:02,  1.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.5786586153720107, \"eval_accuracy\": 0.8736517719568567, \"learning_rate\": 1.9262295081967212e-05, \"loss\": 0.07866687266621739, \"step\": 150}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  46%|████▌     | 28/61 [00:58<02:45,  5.03s/it]\u001b[A\n",
            "Training Batch Iteration:  48%|████▊     | 29/61 [01:00<02:05,  3.92s/it]\u001b[A\n",
            "Training Batch Iteration:  49%|████▉     | 30/61 [01:01<01:37,  3.15s/it]\u001b[A\n",
            "Training Batch Iteration:  51%|█████     | 31/61 [01:02<01:16,  2.54s/it]\u001b[A\n",
            "Training Batch Iteration:  52%|█████▏    | 32/61 [01:03<01:00,  2.09s/it]\u001b[A\n",
            "Training Batch Iteration:  54%|█████▍    | 33/61 [01:04<00:49,  1.76s/it]\u001b[A\n",
            "Training Batch Iteration:  56%|█████▌    | 34/61 [01:05<00:41,  1.53s/it]\u001b[A\n",
            "Training Batch Iteration:  57%|█████▋    | 35/61 [01:06<00:37,  1.46s/it]\u001b[A\n",
            "Training Batch Iteration:  59%|█████▉    | 36/61 [01:08<00:34,  1.39s/it]\u001b[A\n",
            "Training Batch Iteration:  61%|██████    | 37/61 [01:09<00:33,  1.41s/it]\u001b[A\n",
            "Training Batch Iteration:  62%|██████▏   | 38/61 [01:10<00:32,  1.40s/it]\u001b[A\n",
            "Training Batch Iteration:  64%|██████▍   | 39/61 [01:12<00:30,  1.36s/it]\u001b[A\n",
            "Training Batch Iteration:  66%|██████▌   | 40/61 [01:13<00:26,  1.26s/it]\u001b[A\n",
            "Training Batch Iteration:  67%|██████▋   | 41/61 [01:14<00:24,  1.24s/it]\u001b[A\n",
            "Training Batch Iteration:  69%|██████▉   | 42/61 [01:15<00:23,  1.25s/it]\u001b[A\n",
            "Training Batch Iteration:  70%|███████   | 43/61 [01:16<00:21,  1.19s/it]\u001b[A\n",
            "Training Batch Iteration:  72%|███████▏  | 44/61 [01:17<00:19,  1.17s/it]\u001b[A\n",
            "Training Batch Iteration:  74%|███████▍  | 45/61 [01:18<00:18,  1.13s/it]\u001b[A\n",
            "Training Batch Iteration:  75%|███████▌  | 46/61 [01:20<00:17,  1.17s/it]\u001b[A\n",
            "Training Batch Iteration:  77%|███████▋  | 47/61 [01:22<00:19,  1.37s/it]\u001b[A\n",
            "Training Batch Iteration:  79%|███████▊  | 48/61 [01:23<00:16,  1.29s/it]\u001b[A\n",
            "Training Batch Iteration:  80%|████████  | 49/61 [01:24<00:14,  1.24s/it]\u001b[A\n",
            "Training Batch Iteration:  82%|████████▏ | 50/61 [01:25<00:13,  1.19s/it]\u001b[A\n",
            "Training Batch Iteration:  84%|████████▎ | 51/61 [01:26<00:11,  1.12s/it]\u001b[A\n",
            "Training Batch Iteration:  85%|████████▌ | 52/61 [01:27<00:10,  1.12s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.11410807844783578, \"eval_accuracy\": 0.9645608628659477, \"learning_rate\": 1.4139344262295081e-05, \"loss\": 0.10108448210172355, \"step\": 175}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  87%|████████▋ | 53/61 [01:41<00:40,  5.11s/it]\u001b[A\n",
            "Training Batch Iteration:  89%|████████▊ | 54/61 [01:43<00:27,  3.94s/it]\u001b[A\n",
            "Training Batch Iteration:  90%|█████████ | 55/61 [01:44<00:18,  3.10s/it]\u001b[A\n",
            "Training Batch Iteration:  92%|█████████▏| 56/61 [01:45<00:12,  2.49s/it]\u001b[A\n",
            "Training Batch Iteration:  93%|█████████▎| 57/61 [01:46<00:08,  2.07s/it]\u001b[A\n",
            "Training Batch Iteration:  95%|█████████▌| 58/61 [01:47<00:05,  1.79s/it]\u001b[A\n",
            "Training Batch Iteration:  97%|█████████▋| 59/61 [01:48<00:03,  1.61s/it]\u001b[A\n",
            "Training Batch Iteration:  98%|█████████▊| 60/61 [01:50<00:01,  1.54s/it]\u001b[A\n",
            "Training Batch Iteration: 100%|██████████| 61/61 [01:51<00:00,  1.82s/it]\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:12,  1.61it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:11,  1.60it/s]\u001b[A\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:10,  1.64it/s]\u001b[A\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:09,  1.73it/s]\u001b[A\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.80it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.72it/s]\u001b[A\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.81it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.77it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 9/21 [00:05<00:06,  1.79it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:06,  1.83it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:06<00:05,  1.83it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:07<00:04,  1.92it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.92it/s]\u001b[A\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.85it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.87it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.91it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.91it/s]\u001b[A\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.89it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.89it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 21/21 [00:11<00:00,  1.90it/s]\n",
            "Epoch:  75%|███████▌  | 3/4 [21:50<09:48, 588.96s/it]\n",
            "Training Batch Iteration:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
            "Training Batch Iteration:   2%|▏         | 1/61 [00:01<01:03,  1.06s/it]\u001b[A\n",
            "Training Batch Iteration:   3%|▎         | 2/61 [00:02<01:03,  1.08s/it]\u001b[A\n",
            "Training Batch Iteration:   5%|▍         | 3/61 [00:03<01:03,  1.09s/it]\u001b[A\n",
            "Training Batch Iteration:   7%|▋         | 4/61 [00:04<01:05,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:   8%|▊         | 5/61 [00:05<01:03,  1.13s/it]\u001b[A\n",
            "Training Batch Iteration:  10%|▉         | 6/61 [00:06<00:58,  1.07s/it]\u001b[A\n",
            "Training Batch Iteration:  11%|█▏        | 7/61 [00:07<00:57,  1.07s/it]\u001b[A\n",
            "Training Batch Iteration:  13%|█▎        | 8/61 [00:08<00:58,  1.10s/it]\u001b[A\n",
            "Training Batch Iteration:  15%|█▍        | 9/61 [00:10<00:58,  1.13s/it]\u001b[A\n",
            "Training Batch Iteration:  16%|█▋        | 10/61 [00:11<00:58,  1.14s/it]\u001b[A\n",
            "Training Batch Iteration:  18%|█▊        | 11/61 [00:12<00:59,  1.19s/it]\u001b[A\n",
            "Training Batch Iteration:  20%|█▉        | 12/61 [00:13<00:59,  1.22s/it]\u001b[A\n",
            "Training Batch Iteration:  21%|██▏       | 13/61 [00:14<00:56,  1.18s/it]\u001b[A\n",
            "Training Batch Iteration:  23%|██▎       | 14/61 [00:15<00:54,  1.16s/it]\u001b[A\n",
            "Training Batch Iteration:  25%|██▍       | 15/61 [00:17<00:55,  1.21s/it]\u001b[A\n",
            "Training Batch Iteration:  26%|██▌       | 16/61 [00:18<00:52,  1.17s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.109706214074755, \"eval_accuracy\": 0.9722650231124808, \"learning_rate\": 9.016393442622952e-06, \"loss\": 0.07073369422927499, \"step\": 200}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  28%|██▊       | 17/61 [00:32<03:46,  5.15s/it]\u001b[A\n",
            "Training Batch Iteration:  30%|██▉       | 18/61 [00:34<02:50,  3.96s/it]\u001b[A\n",
            "Training Batch Iteration:  31%|███       | 19/61 [00:35<02:10,  3.11s/it]\u001b[A\n",
            "Training Batch Iteration:  33%|███▎      | 20/61 [00:36<01:44,  2.54s/it]\u001b[A\n",
            "Training Batch Iteration:  34%|███▍      | 21/61 [00:37<01:24,  2.11s/it]\u001b[A\n",
            "Training Batch Iteration:  36%|███▌      | 22/61 [00:38<01:10,  1.81s/it]\u001b[A\n",
            "Training Batch Iteration:  38%|███▊      | 23/61 [00:39<01:01,  1.63s/it]\u001b[A\n",
            "Training Batch Iteration:  39%|███▉      | 24/61 [00:40<00:54,  1.47s/it]\u001b[A\n",
            "Training Batch Iteration:  41%|████      | 25/61 [00:42<00:51,  1.43s/it]\u001b[A\n",
            "Training Batch Iteration:  43%|████▎     | 26/61 [00:43<00:48,  1.39s/it]\u001b[A\n",
            "Training Batch Iteration:  44%|████▍     | 27/61 [00:44<00:45,  1.32s/it]\u001b[A\n",
            "Training Batch Iteration:  46%|████▌     | 28/61 [00:45<00:42,  1.28s/it]\u001b[A\n",
            "Training Batch Iteration:  48%|████▊     | 29/61 [00:46<00:38,  1.20s/it]\u001b[A\n",
            "Training Batch Iteration:  49%|████▉     | 30/61 [00:48<00:39,  1.27s/it]\u001b[A\n",
            "Training Batch Iteration:  51%|█████     | 31/61 [00:49<00:36,  1.23s/it]\u001b[A\n",
            "Training Batch Iteration:  52%|█████▏    | 32/61 [00:50<00:34,  1.20s/it]\u001b[A\n",
            "Training Batch Iteration:  54%|█████▍    | 33/61 [00:51<00:35,  1.26s/it]\u001b[A\n",
            "Training Batch Iteration:  56%|█████▌    | 34/61 [00:53<00:33,  1.23s/it]\u001b[A\n",
            "Training Batch Iteration:  57%|█████▋    | 35/61 [00:54<00:29,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:  59%|█████▉    | 36/61 [00:55<00:28,  1.13s/it]\u001b[A\n",
            "Training Batch Iteration:  61%|██████    | 37/61 [00:56<00:26,  1.10s/it]\u001b[A\n",
            "Training Batch Iteration:  62%|██████▏   | 38/61 [00:57<00:24,  1.06s/it]\u001b[A\n",
            "Training Batch Iteration:  64%|██████▍   | 39/61 [00:58<00:22,  1.02s/it]\u001b[A\n",
            "Training Batch Iteration:  66%|██████▌   | 40/61 [00:59<00:21,  1.03s/it]\u001b[A\n",
            "Training Batch Iteration:  67%|██████▋   | 41/61 [01:00<00:21,  1.08s/it]\u001b[A\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  2.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  2.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:07<00:03,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  81%|████████  | 17/21 [00:08<00:02,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"eval_loss\": 0.12642938399776107, \"eval_accuracy\": 0.9691833590138675, \"learning_rate\": 3.89344262295082e-06, \"loss\": 0.016114526093006135, \"step\": 225}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Batch Iteration:  69%|██████▉   | 42/61 [01:14<01:34,  4.96s/it]\u001b[A\n",
            "Training Batch Iteration:  70%|███████   | 43/61 [01:15<01:08,  3.81s/it]\u001b[A\n",
            "Training Batch Iteration:  72%|███████▏  | 44/61 [01:16<00:50,  3.00s/it]\u001b[A\n",
            "Training Batch Iteration:  74%|███████▍  | 45/61 [01:17<00:39,  2.44s/it]\u001b[A\n",
            "Training Batch Iteration:  75%|███████▌  | 46/61 [01:18<00:31,  2.08s/it]\u001b[A\n",
            "Training Batch Iteration:  77%|███████▋  | 47/61 [01:20<00:25,  1.79s/it]\u001b[A\n",
            "Training Batch Iteration:  79%|███████▊  | 48/61 [01:21<00:20,  1.61s/it]\u001b[A\n",
            "Training Batch Iteration:  80%|████████  | 49/61 [01:22<00:18,  1.53s/it]\u001b[A\n",
            "Training Batch Iteration:  82%|████████▏ | 50/61 [01:23<00:15,  1.39s/it]\u001b[A\n",
            "Training Batch Iteration:  84%|████████▎ | 51/61 [01:24<00:12,  1.29s/it]\u001b[A\n",
            "Training Batch Iteration:  85%|████████▌ | 52/61 [01:25<00:11,  1.22s/it]\u001b[A\n",
            "Training Batch Iteration:  87%|████████▋ | 53/61 [01:26<00:09,  1.19s/it]\u001b[A\n",
            "Training Batch Iteration:  89%|████████▊ | 54/61 [01:27<00:08,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:  90%|█████████ | 55/61 [01:29<00:06,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:  92%|█████████▏| 56/61 [01:30<00:05,  1.15s/it]\u001b[A\n",
            "Training Batch Iteration:  93%|█████████▎| 57/61 [01:31<00:05,  1.32s/it]\u001b[A\n",
            "Training Batch Iteration:  95%|█████████▌| 58/61 [01:33<00:03,  1.31s/it]\u001b[A\n",
            "Training Batch Iteration:  97%|█████████▋| 59/61 [01:35<00:02,  1.45s/it]\u001b[A\n",
            "Training Batch Iteration:  98%|█████████▊| 60/61 [01:36<00:01,  1.33s/it]\u001b[A\n",
            "Training Batch Iteration: 100%|██████████| 61/61 [01:37<00:00,  1.59s/it]\n",
            "\n",
            "Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   5%|▍         | 1/21 [00:00<00:10,  1.94it/s]\u001b[A\n",
            "Evaluating:  10%|▉         | 2/21 [00:01<00:09,  1.90it/s]\u001b[A\n",
            "Evaluating:  14%|█▍        | 3/21 [00:01<00:09,  1.94it/s]\u001b[A\n",
            "Evaluating:  19%|█▉        | 4/21 [00:02<00:08,  1.97it/s]\u001b[A\n",
            "Evaluating:  24%|██▍       | 5/21 [00:02<00:08,  1.97it/s]\u001b[A\n",
            "Evaluating:  29%|██▊       | 6/21 [00:03<00:08,  1.83it/s]\u001b[A\n",
            "Evaluating:  33%|███▎      | 7/21 [00:03<00:07,  1.86it/s]\u001b[A\n",
            "Evaluating:  38%|███▊      | 8/21 [00:04<00:07,  1.80it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 9/21 [00:04<00:06,  1.80it/s]\u001b[A\n",
            "Evaluating:  48%|████▊     | 10/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
            "Evaluating:  52%|█████▏    | 11/21 [00:05<00:05,  1.84it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 12/21 [00:06<00:04,  1.84it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 13/21 [00:06<00:04,  1.94it/s]\u001b[A\n",
            "Evaluating:  67%|██████▋   | 14/21 [00:07<00:03,  1.93it/s]\u001b[A\n",
            "Evaluating:  71%|███████▏  | 15/21 [00:08<00:03,  1.85it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 16/21 [00:08<00:02,  1.86it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 17/21 [00:09<00:02,  1.90it/s]\u001b[A\n",
            "Evaluating:  86%|████████▌ | 18/21 [00:09<00:01,  1.90it/s]\u001b[A\n",
            "Evaluating:  90%|█████████ | 19/21 [00:10<00:01,  1.89it/s]\u001b[A\n",
            "Evaluating:  95%|█████████▌| 20/21 [00:10<00:00,  1.89it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  1.95it/s]\n",
            "Epoch: 100%|██████████| 4/4 [23:38<00:00, 354.66s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se45Ve33_KAr"
      },
      "source": [
        "## Evaluating on the Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo2zxNJDYbmh",
        "outputId": "2ae5686b-d897-4a98-8630-43884a3ed697"
      },
      "source": [
        "# Evaluation\n",
        "results = {}\n",
        "if args.do_eval:\n",
        "    checkpoints = [args.output_dir]\n",
        "    if args.eval_all_checkpoints:\n",
        "        checkpoints = list(os.path.dirname(c) \n",
        "        for c in sorted(glob.glob(args.output_dir + \"/**/\" + \n",
        "                                  WEIGHTS_NAME, recursive=False)))\n",
        "        # recursive=False because otherwise the parent diretory gets included\n",
        "        # which is not what we want; only subdirectories\n",
        "\n",
        "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "\n",
        "    for checkpoint in checkpoints:\n",
        "        global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "        prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "        model = MMBTForClassification(transformer_config, multimodal_config)\n",
        "        checkpoint = os.path.join(checkpoint, 'pytorch_model.bin')\n",
        "        model.load_state_dict(torch.load(checkpoint))\n",
        "        model.to(args.device)\n",
        "        result = evaluate(args, model, tokenizer, evaluate=True, test=True, prefix=prefix)\n",
        "        result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "        results.update(result)\n",
        "\n",
        "results.keys()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 21/21 [03:58<00:00, 11.38s/it]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.02it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.04it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.04it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.04it/s]\n",
            "Evaluating: 100%|██████████| 21/21 [00:10<00:00,  2.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss_100', 'accuracy_100', 'loss_125', 'accuracy_125', 'loss_150', 'accuracy_150', 'loss_175', 'accuracy_175', 'loss_200', 'accuracy_200', 'loss_225', 'accuracy_225', 'loss_25', 'accuracy_25', 'loss_50', 'accuracy_50', 'loss_75', 'accuracy_75'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu5ge_8Yjg6w",
        "outputId": "056f79ad-d3e7-4fc7-dc70-7d91cfc855a9"
      },
      "source": [
        "results"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy_100': 0.9492307692307692,\n",
              " 'accuracy_125': 0.963076923076923,\n",
              " 'accuracy_150': 0.9046153846153846,\n",
              " 'accuracy_175': 0.9692307692307692,\n",
              " 'accuracy_200': 0.9646153846153847,\n",
              " 'accuracy_225': 0.9692307692307692,\n",
              " 'accuracy_25': 0.8969230769230769,\n",
              " 'accuracy_50': 0.9461538461538461,\n",
              " 'accuracy_75': 0.963076923076923,\n",
              " 'loss_100': 0.13056670280084723,\n",
              " 'loss_125': 0.15960173424155938,\n",
              " 'loss_150': 0.4642904294388635,\n",
              " 'loss_175': 0.1228057337215259,\n",
              " 'loss_200': 0.1284510674221175,\n",
              " 'loss_225': 0.1478217844407828,\n",
              " 'loss_25': 0.2989686181147893,\n",
              " 'loss_50': 0.15678607938545092,\n",
              " 'loss_75': 0.16127859109214374}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMeqM4JD_bbV"
      },
      "source": [
        "## Saving Test Eval Results\n",
        "\n",
        "The code automatically saved evaluation result from each checkpoint in its respective folder. This next cell simply saves all of them in one place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvH1zD7si_rg"
      },
      "source": [
        "with open('mmbt_both_front_eval_results.txt', mode='w', encoding='utf-8') as out_f:\n",
        "    print(results, file=out_f)"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}